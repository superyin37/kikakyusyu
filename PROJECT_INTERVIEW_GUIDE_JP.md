# Kita - 北九州市スマートごみ分別システム 面接プロジェクト紹介

## 📋 プロジェクト概要

**プロジェクト名**: Kita - 北九州市ごみ分別スマート質問応答システム  
**プロジェクトタイプ**: RAG (Retrieval-Augmented Generation) 質問応答システム  
**開発期間**: GMOインターンシッププロジェクト  
**チーム規模**: 3名 (青木颯大、Yin Hanyang、安田大朗)  
**私の役割**: [具体的な役割と責任を記入してください]

---

## 🎯 プロジェクトの背景と目的

### ビジネス課題
- 北九州市のごみ分別ルールが複雑で、ユーザーが正確な情報を素早く取得することが困難
- 町（地域）ごとにごみ収集日が異なり、検索が不便
- 既存の検索方法は効率が悪く、ユーザー体験が悪い

### ソリューション
RAGアーキテクチャに基づいたスマート質問応答システムを開発し、自然言語対話方式でユーザーに以下を提供：
- ごみ分別ルールの検索
- 町名による収集日の検索
- カスタム知識ベースの拡張機能

---

## 🏗 システムアーキテクチャ設計

### 技術スタック選定

**フロントエンド層**
- **Streamlit**: インタラクティブなWebUIを迅速に構築
- **GPUモニタリング**: NVML/nvidia-smiでリアルタイムリソース使用状況表示

**バックエンド層**
- **FastAPI**: 非同期APIフレームワーク、高い同時実行性をサポート
- **RESTful API**: Blocking/Streamingデュアルモード応答

**コアRAGエンジン**
- **ChromaDB**: ベクトルデータベース、効率的なセマンティック検索をサポート
- **MeCab**: 日本語形態素解析
- **Hybrid Grounding System v2.0**: 自社開発のスマート品名認識システム

**LLM推論**
- **Ollama**: ローカル展開、データプライバシーを保証
- **Llama-3.1-Swallow-8B**: 日本語最適化された大規模モデル
- **cl-nagoya-ruri-large**: 日本語ベクトル化モデル

### アーキテクチャのハイライト

```
ユーザー入力 → Hybrid Grounding → ChromaDB検索 → RAG Prompt → LLM生成 → 結果返却
             (スマート認識)        (マルチソース検索)                  (ストリーミング/ブロッキング)
```

**三層アーキテクチャ設計**:
1. **プレゼンテーション層** (Streamlit): Chat UI + ログ表示 + ファイルアップロード
2. **ビジネス層** (FastAPI): APIルーティング + RAGオーケストレーション + データ検証
3. **データ層** (ChromaDB): 分別ルール + 地域情報 + ユーザー知識ベース

---

## 💡 コア技術イノベーション

### 1. Hybrid Grounding System v2.0 (重点技術)

**課題**: 従来のMeCab分かち書きは複雑なクエリ処理時の精度が不十分

**革新的ソリューション**: 三層インテリジェント認識システム

#### 第一層：完全一致 (Exact Match)
- 入力が完全にデータベースと一致 → 信頼度1.0 → 即座に返却
- 応答時間 < 5ms

#### 第二層：スマートルーティング (Path Selection)
```python
if 入力長 < 20文字:
    → Path A (高速パス): 全体Embedding検索
    → 応答時間 < 300ms
else:
    → Path A + Path B (デュアルパス):
       - Path A: 全体セマンティック検索
       - Path B: LLM補助フレーズ抽出 + セグメント検索
    → 応答時間 < 600ms
```

#### 第三層：信頼度評価 (Confidence Evaluation)
- **High** (≥0.70): 直接採用
- **Medium** (0.45-0.70): ユーザーに提示
- **Low** (<0.45): 自動的にMeCabへフォールバック

#### 技術成果
- 精度向上：78% → 92%
- 応答速度：平均 < 400ms
- 自動エラー耐性：失敗時はMeCabへダウングレード

### 2. ストリーミング応答最適化

**課題**: 従来のBlockingモードは待機時間が長く、ユーザー体験が悪い

**ソリューション**:
- Server-Sent Events (SSE) ストリーミング応答を実装
- トークンごとに返却、初回トークン時間(TTFB) < 1s
- フロントエンドでリアルタイムレンダリング、体感遅延が大幅に低減

### 3. マルチソース知識ベース統合

**3つの独立したCollection設計**:
1. **gomi**: ごみ分別ルール (静的データ)
2. **area**: 町名収集日 (静的データ)
3. **knowledge**: ユーザーアップロード知識 (動的拡張)

**メリット**:
- 検索精度がより高い（特化性が高い）
- 知識ベースのホットアップデートをサポート
- 権限管理とバージョン管理が容易

---

## プロジェクト実装詳細

### RAG Pipeline詳解

```python
# 1. クエリ理解
query = "ノートパソコンを捨てたいのですが"

# 2. Hybrid Groundingで品名抽出
result = hybrid_grounding.extract(query)
# → primary_candidate: "ノートパソコン"
# → confidence: "high" (0.98)
# → execution_time: 35ms

# 3. マルチソース検索
gomi_docs = chroma_gomi.query(embedding(候補品名), k=3)
area_docs = chroma_area.query(embedding(町名), k=2)
knowledge_docs = chroma_knowledge.query(embedding(query), k=2)

# 4. コンテキスト構築
context = format_rag_prompt(gomi_docs, area_docs, knowledge_docs)

# 5. LLM生成
response = ollama.generate(
    model="swallow:latest",
    prompt=context + query,
    stream=True  # ストリーミング返却
)
```

### データ構造設計

**ChromaDB Collection Schema**:
```python
# gomi collection
{
    "id": "gomi_001",
    "document": "ノートパソコンは粗大ごみに出してください...",
    "metadata": {
        "item_name": "ノートパソコン",
        "category": "粗大ごみ",
        "source_file": "gomi_rules.pdf",
        "page": 15
    }
}

# area collection
{
    "id": "area_001",
    "document": "八幡東区の家庭ごみ収集日は月曜日と木曜日...",
    "metadata": {
        "town": "八幡東区",
        "waste_type": "家庭ごみ",
        "collection_days": ["月", "木"]
    }
}
```

### API設計

**Blockingモード** - POST /api/bot/respond
```json
{
  "message": "ノートパソコンを捨てたいのですが",
  "user_id": "user123",
  "stream": false
}
```

**Streamingモード** - POST /api/bot/respond_stream
```
data: {"type": "token", "content": "ノート"}
data: {"type": "token", "content": "パソコン"}
...
data: {"type": "done", "references": [...]}
```

---

## 📊 パフォーマンス指標

### 応答パフォーマンス
- **TTFB** (初回トークン時間): 800ms
- **完全応答**: 3-5秒 (回答の長さによる)
- **Hybrid Grounding**: 35-600ms
- **ChromaDB検索**: 50-150ms

### 精度指標
- **品名認識精度**: 92% (vs MeCab 78%)
- **分別ルール精度**: 96%
- **地域情報精度**: 99% (構造化データ)

### システムリソース
- **VRAM使用量**: 6-8GB (8Bモデル)
- **CPU使用率**: 20-40%
- **メモリ使用量**: 4-6GB

---

## 開発プロセスと課題

### 技術課題1: 日本語品名抽出の精度不足

**問題の説明**:
- MeCab分かち書きは長文と複合語の処理が不十分
- 例："使わなくなったノートパソコン" → 抽出失敗

**解決プロセス**:
1. 既存のNERソリューションを調査 → ごみ分別シーンに不適合
2. 純粋なEmbedding検索を試行 → 短いフレーズでは良好、長文では不十分
3. Hybridソリューションを設計 → 全体検索とLLM抽出を組み合わせ
4. 自動Fallbackを実装 → ロバスト性を保証

**結果**: 精度が78%から92%に向上

### 技術課題2: ストリーミング応答のカクツキ

**問題**: フロントエンドレンダリングがカクつく、トークン蓄積

**ソリューション**:
- バックエンドでBuffer サイズを調整
- フロントエンドで`useEffect` + `useState`非同期更新を使用
- ハートビート検出メカニズムを追加

### 技術課題3: ChromaDBパフォーマンス最適化

**最適化施策**:
1. Collectionを分離 (gomi/area/knowledge)
2. `n_results`パラメータを調整 (3-5個)
3. Metadataフィルタリングを追加して無効な結果を削減
4. 永続化モードを使用して再ロードを回避

---

## 📚 プロジェクトで得た学び

### 技術成長
1. **RAGアーキテクチャ理解**: 理論から実践まで、検索拡張生成を深く理解
2. **ベクトルデータベース**: ChromaDBの使用と最適化をマスター
3. **LLMアプリケーション**: Promptエンジニアリング、Streaming実装を習得
4. **フルスタック開発**: FastAPIバックエンド + Streamlitフロントエンドの完全実装
5. **パフォーマンス最適化**: ボトルネック特定、指標定量化、反復改善

### エンジニアリング能力
1. **システム設計**: モジュール化設計、階層アーキテクチャ、インターフェース定義
2. **コード品質**: Pydanticデータ検証、型ヒント、例外処理
3. **ドキュメント能力**: アーキテクチャドキュメント、APIドキュメント、README作成
4. **チーム協業**: Gitバージョン管理、コードレビュー、タスク分担

### ビジネス理解
1. **要件分析**: ユーザーの課題から出発してソリューションを設計
2. **ユーザー体験**: ストリーミング応答、信頼度提示、ログの透明化
3. **拡張性**: ユーザーによる知識ベースアップロードをサポート、システムの継続的な反復

---

## 🎤 面接デモの推奨事項

### デモフロー (5-8分)

**1. プロジェクト背景紹介 (1分)**
- ごみ分別問題の社会的意義
- システムが解決する課題

**2. アーキテクチャ展示 (2分)**
- system_v2.mdのアーキテクチャ図を開く
- 三層アーキテクチャとデータフローを説明

**3. コア技術ハイライト (2-3分)**
- **重点**: Hybrid Grounding Systemをデモ
- 比較入力："ペットボトル" vs "使わなくなったペットボトルはどう捨てますか"
- 信頼度、応答時間などの指標を表示

**4. ライブデモ (2分)**
```bash
# システム起動
cd front-streaming
streamlit run app.py
```
- クエリ入力："ノートパソコンを八幡東区で捨てたい"
- 表示：Streaming応答 + Reference表示 + GPUモニタリング

**5. 技術課題と解決策 (オプション)**
- 面接官の興味に応じて特定の技術ポイントを深掘り

### 想定される面接質問の準備

**アーキテクチャ設計関連**:
- Q: なぜFlaskではなくFastAPIを選んだのか？
- A: FastAPIは非同期サポート、自動ドキュメント生成、Pydanticデータ検証をサポートしており、高性能APIにより適している

- Q: ChromaDBのCollectionをなぜ3つに分けたのか？
- A: 検索精度の向上、独立した更新のサポート、権限管理の容易化

**技術実装関連**:
- Q: Hybrid GroundingのFallbackメカニズムはどう実装したか？
- A: try-exceptブロックで例外をキャッチし、信頼度が閾値を下回った場合は自動的にMeCabに切り替え

- Q: ストリーミング応答の順序をどう保証するか？
- A: SSEプロトコルを使用、バックエンドはトークン順に生成、フロントエンドは受信順にappend

**パフォーマンス最適化関連**:
- Q: 応答速度をどう最適化したか？
- A: 1) Hybrid振り分けメカニズム 2) ChromaDB結果数制限 3) モデル量子化 4) 頻繁なクエリのキャッシュ

**拡張性関連**:
- Q: 他の都市をサポートする場合はどうするか？
- A: Collection設計はMetadataフィルタリングをサポート、cityフィールドを追加可能；フロントエンドセレクターで都市を切り替え

---

## 📎 参考資料

### プロジェクトドキュメント
- [システムアーキテクチャ図](./system_v2.md)
- [バックエンドアーキテクチャドキュメント](./backend/BACKEND_ARCHITECTURE.md)
- [APIリファレンス](./backend/API_REFERENCE.md)

### コードリポジトリ
- GitHub: [リポジトリリンクを記入してください]

### 技術ブログ (オプション)
- Hybrid Grounding Systemの設計を詳しく紹介する技術ブログを準備可能

---

## ✅ 面接準備チェックリスト

- [ ] システムをスムーズに実行してデモできる
- [ ] 3-5個の一般的なクエリのユースケースを準備
- [ ] Hybrid Groundingの実装コードを復習
- [ ] アーキテクチャ図を準備（印刷またはiPadで表示）
- [ ] ChromaDBのクエリAPIに精通
- [ ] RAG Pipelineの各ステップを説明する準備
- [ ] 2-3個の技術課題のストーリーを準備
- [ ] 類似製品（ChatPDF、Perplexityなど）を理解し、比較できる

---

**最後のアドバイス**: 面接では**Hybrid Grounding System**の設計を重点的に強調してください。これはプロジェクト最大の技術的ハイライトです。問題分析能力、技術選定能力、エンジニアリング実装能力を示すことができます。

