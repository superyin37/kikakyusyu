# å‰ç«¯å¿«é€Ÿå‚è€ƒæ‰‹å†Œ

## æ–‡æ¡£æ¦‚è¿°
æœ¬æ–‡æ¡£æä¾›Kitaå‰ç«¯WebUIçš„å¿«é€Ÿå‚è€ƒï¼ŒåŒ…æ‹¬ç»„ä»¶ä½¿ç”¨ã€é…ç½®å‚æ•°ã€å¸¸è§é—®é¢˜å’Œä»£ç ç¤ºä¾‹ã€‚

---

## ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)
2. [UIç»„ä»¶å‚è€ƒ](#2-uiç»„ä»¶å‚è€ƒ)
3. [åŠŸèƒ½æ¨¡å—](#3-åŠŸèƒ½æ¨¡å—)
4. [é…ç½®å‚æ•°](#4-é…ç½®å‚æ•°)
5. [ä»£ç ç¤ºä¾‹](#5-ä»£ç ç¤ºä¾‹)
6. [å¸¸è§é—®é¢˜](#6-å¸¸è§é—®é¢˜)
7. [æ€§èƒ½ä¼˜åŒ–](#7-æ€§èƒ½ä¼˜åŒ–)
8. [è°ƒè¯•æŠ€å·§](#8-è°ƒè¯•æŠ€å·§)

---

## 1. å¿«é€Ÿå¼€å§‹

### 1.1 å¯åŠ¨å‰ç«¯

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd d:\projects\kitakyusyu\gmo_intern-main\gmo_intern-main

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚æœä½¿ç”¨ï¼‰
.\.venv\Scripts\Activate.ps1

# å¯åŠ¨Streamlit
streamlit run front-streaming/app.py
```

**é»˜è®¤è®¿é—®åœ°å€**: http://localhost:8501

### 1.2 å‰ææ¡ä»¶

- Python 3.10+
- åç«¯APIè¿è¡Œåœ¨ http://localhost:8000
- å·²å®‰è£…ä¾èµ–ï¼š
  ```bash
  pip install streamlit requests pynvml
  ```

### 1.3 ç›®å½•ç»“æ„

```
front-streaming/
â”œâ”€â”€ app.py              # ä¸»åº”ç”¨
â”œâ”€â”€ gpu_stats.py        # GPUç›‘æ§æ¨¡å—
â””â”€â”€ knowledge_files/    # ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆè¿è¡Œæ—¶åˆ›å»ºï¼‰
```

---

## 2. UIç»„ä»¶å‚è€ƒ

### 2.1 å¯¹è¯ç»„ä»¶

#### st.chat_message

æ˜¾ç¤ºå¯¹è¯æ¶ˆæ¯ï¼Œè‡ªåŠ¨æ·»åŠ å¤´åƒå’Œæ ·å¼ã€‚

**ç”¨æ³•**:
```python
with st.chat_message("user"):
    st.markdown("ç”¨æˆ·çš„æ¶ˆæ¯å†…å®¹")

with st.chat_message("assistant"):
    st.markdown("åŠ©æ‰‹çš„å›ç­”å†…å®¹")
```

**è§’è‰²ç±»å‹**:
- `"user"`: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå³ä¾§ï¼Œè“è‰²ï¼‰
- `"assistant"`: åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå·¦ä¾§ï¼Œç°è‰²ï¼‰

#### st.chat_input

å›ºå®šåœ¨åº•éƒ¨çš„è¾“å…¥æ¡†ã€‚

**ç”¨æ³•**:
```python
user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if user_input:
    # å¤„ç†ç”¨æˆ·è¾“å…¥
    print(user_input)
```

### 2.2 ä¾§è¾¹æ ç»„ä»¶

#### st.sidebar

åˆ›å»ºä¾§è¾¹æ ã€‚

**ç”¨æ³•**:
```python
with st.sidebar:
    st.subheader("è®¾ç½®")
    mode = st.radio("æ¨¡å¼", ["Blocking", "Streaming"])
```

#### st.radio

å•é€‰æŒ‰é’®ã€‚

**ç”¨æ³•**:
```python
mode = st.radio(
    "å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
    ["Blocking", "Streaming"],
    horizontal=True,  # æ°´å¹³æ’åˆ—
    key="response_mode"
)
```

#### st.file_uploader

æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ã€‚

**ç”¨æ³•**:
```python
upload_file = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["txt", "pdf", "csv", "json"],
    accept_multiple_files=False
)

if upload_file is not None:
    # è·å–æ–‡ä»¶å†…å®¹
    content = upload_file.read()
    # è·å–æ–‡ä»¶å
    filename = upload_file.name
```

### 2.3 æŒ‡æ ‡ç»„ä»¶

#### st.metric

æ˜¾ç¤ºæŒ‡æ ‡å¡ç‰‡ã€‚

**ç”¨æ³•**:
```python
st.metric(
    label="TTFB (s)",
    value="2.34",
    delta="-0.5"  # å¯é€‰ï¼šå˜åŒ–å€¼
)
```

**ç¤ºä¾‹**:
```python
col1, col2, col3 = st.columns(3)
col1.metric("TTFB", "2.34s")
col2.metric("Total", "5.67s")
col3.metric("Tokens", "1250")
```

### 2.4 å¸ƒå±€ç»„ä»¶

#### st.columns

åˆ›å»ºåˆ—å¸ƒå±€ã€‚

**ç”¨æ³•**:
```python
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("æŒ‡æ ‡1", "100")
with col2:
    st.metric("æŒ‡æ ‡2", "200")
# ...
```

#### st.empty

åˆ›å»ºå ä½ç¬¦ï¼Œå¯åç»­æ›´æ–°ã€‚

**ç”¨æ³•**:
```python
placeholder = st.empty()

# åˆå§‹æ˜¾ç¤º
placeholder.text("åŠ è½½ä¸­...")

# æ›´æ–°å†…å®¹
placeholder.markdown("å®Œæˆï¼")
```

#### st.expander

å¯å±•å¼€/æŠ˜å çš„å®¹å™¨ã€‚

**ç”¨æ³•**:
```python
with st.expander("æŸ¥çœ‹è¯¦æƒ…"):
    st.write("è¿™é‡Œæ˜¯è¯¦ç»†å†…å®¹")
```

### 2.5 æ¶ˆæ¯ç»„ä»¶

#### st.success / st.error / st.warning / st.info

æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯ã€‚

**ç”¨æ³•**:
```python
st.success("âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
st.warning("âš ï¸ è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
st.info("â„¹ï¸ æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
```

---

## 3. åŠŸèƒ½æ¨¡å—

### 3.1 å¯¹è¯åŠŸèƒ½

#### å‘é€æ¶ˆæ¯

```python
user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if user_input:
    # 1. æ·»åŠ åˆ°å†å²
    st.session_state["messages"].append({
        "role": "user",
        "content": user_input
    })
    
    # 2. è°ƒç”¨API
    response = call_api(user_input)
    
    # 3. æ˜¾ç¤ºå›ç­”
    st.session_state["messages"].append({
        "role": "assistant",
        "content": response
    })
```

#### æ˜¾ç¤ºå†å²

```python
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
```

### 3.2 æ¨¡å¼åˆ‡æ¢

```python
mode = st.radio(
    "å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
    ["Blocking", "Streaming"],
    horizontal=True
)

if mode == "Blocking":
    # Blockingæ¨¡å¼å¤„ç†
    response = requests.post("http://localhost:8000/api/bot/respond", ...)
else:
    # Streamingæ¨¡å¼å¤„ç†
    with requests.post("http://localhost:8000/api/bot/respond_stream", stream=True) as res:
        for chunk in res.iter_content():
            # å®æ—¶æ˜¾ç¤º
            ...
```

### 3.3 æ–‡ä»¶ä¸Šä¼ 

```python
upload_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf", "txt"])

if upload_file is not None:
    # ä¿å­˜æ–‡ä»¶
    save_path = KNOWLEDGE_DIR / upload_file.name
    with open(save_path, "wb") as f:
        f.write(upload_file.getbuffer())
    
    # æ·»åŠ åˆ°ChromaDB
    from rag.user_knowledge import add_file_to_chroma
    add_file_to_chroma(save_path)
    
    st.success(f"âœ… {upload_file.name} ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
```

### 3.4 GPUç›‘æ§

```python
from gpu_stats import init_nvml_once, get_gpu_stats

# åˆå§‹åŒ–
init_nvml_once()

# è·å–çŠ¶æ€
stats = get_gpu_stats()
if stats:
    used_gb, total_gb, util_p, name = stats
    st.metric("VRAM (GB)", f"{used_gb:.2f}/{total_gb:.2f}")
    st.caption(f"{name} | Util {util_p}%")
else:
    st.metric("VRAM (GB)", "N/A")
```

---

## 4. é…ç½®å‚æ•°

### 4.1 Streamlité…ç½®

åˆ›å»º `.streamlit/config.toml`:

```toml
[server]
port = 8501
address = "0.0.0.0"
headless = true
maxUploadSize = 200  # MB

[theme]
primaryColor = "#FF4B4B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"

[browser]
gatherUsageStats = false
serverAddress = "localhost"
```

### 4.2 åº”ç”¨é…ç½®

**æ–‡ä»¶**: `front-streaming/app.py`

```python
# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Llama Chat",
    page_icon="â±ï¸",
    layout="centered",  # "centered" | "wide"
    initial_sidebar_state="auto"  # "auto" | "expanded" | "collapsed"
)

# æ—¥å¿—æ–‡ä»¶
LOG_FILE = Path("backend/logs.jsonl")

# çŸ¥è¯†æ–‡ä»¶ç›®å½•
KNOWLEDGE_DIR = Path("knowledge_files")

# APIåœ°å€
API_BASE_URL = "http://localhost:8000"
```

### 4.3 APIç«¯ç‚¹

| ç«¯ç‚¹ | ç”¨é€” | URL |
|-----|------|-----|
| Blocking | ä¸€æ¬¡æ€§è¿”å›å®Œæ•´å›ç­” | `http://localhost:8000/api/bot/respond` |
| Streaming | æµå¼è¿”å›å›ç­” | `http://localhost:8000/api/bot/respond_stream` |

### 4.4 è¶…æ—¶è®¾ç½®

```python
# Blockingæ¨¡å¼
response = requests.post(url, json=payload, timeout=20)  # 20ç§’

# Streamingæ¨¡å¼
with requests.post(url, json=payload, stream=True, timeout=60) as res:  # 60ç§’
    ...
```

---

## 5. ä»£ç ç¤ºä¾‹

### 5.1 å®Œæ•´çš„Blockingè¯·æ±‚

```python
import streamlit as st
import requests
import time

st.title("RAG ãƒãƒ£ãƒƒãƒˆ")

user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›")

if user_input:
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
    with st.chat_message("assistant"):
        placeholder = st.empty()
        
        try:
            # è°ƒç”¨API
            start = time.perf_counter()
            response = requests.post(
                "http://localhost:8000/api/bot/respond",
                json={"prompt": user_input},
                timeout=20
            )
            response.raise_for_status()
            elapsed = time.perf_counter() - start
            
            # è§£æå“åº”
            data = response.json()
            reply = data.get("reply", "")
            references = data.get("references", [])
            
            # æ˜¾ç¤ºå›ç­”
            placeholder.markdown(reply)
            
            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            st.caption(f"â±ï¸ å¿œç­”æ™‚é–“: {elapsed:.2f}s")
            
            # æ˜¾ç¤ºå‚è€ƒä¿¡æ¯
            if references:
                with st.expander("ğŸ“‘ å‚è€ƒæƒ…å ±"):
                    for ref in references:
                        st.markdown(f"- **{ref['file']}** p.{ref['page']}")
                        st.markdown(f"> {ref['text'][:200]}...")
        
        except Exception as e:
            placeholder.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
```

### 5.2 å®Œæ•´çš„Streamingè¯·æ±‚

```python
import streamlit as st
import requests
import time
import json

st.title("RAG ãƒãƒ£ãƒƒãƒˆ (Streaming)")

user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)
    
    with st.chat_message("assistant"):
        placeholder = st.empty()
        
        try:
            start = time.perf_counter()
            ttfb = None
            collected = ""
            
            with requests.post(
                "http://localhost:8000/api/bot/respond_stream",
                json={"prompt": user_input},
                stream=True,
                timeout=60
            ) as response:
                response.raise_for_status()
                
                # é€å—æ¥æ”¶
                for chunk in response.iter_content(chunk_size=None):
                    if not chunk:
                        continue
                    
                    # è®°å½•TTFB
                    if ttfb is None:
                        ttfb = time.perf_counter() - start
                    
                    # å®æ—¶æ˜¾ç¤º
                    text = chunk.decode("utf-8")
                    collected += text
                    placeholder.markdown(collected)
                
                elapsed = time.perf_counter() - start
                
                # æ˜¾ç¤ºæŒ‡æ ‡
                col1, col2 = st.columns(2)
                col1.metric("TTFB", f"{ttfb:.2f}s")
                col2.metric("Total", f"{elapsed:.2f}s")
                
                # è§£æReferences
                refs_header = response.headers.get("X-References", "[]")
                references = json.loads(refs_header)
                
                if references:
                    with st.expander("ğŸ“‘ å‚è€ƒæƒ…å ±"):
                        for ref in references:
                            st.markdown(f"- **{ref['file']}** p.{ref['page']}")
        
        except Exception as e:
            placeholder.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
```

### 5.3 GPUç›‘æ§é›†æˆ

```python
import streamlit as st
from gpu_stats import init_nvml_once, get_gpu_stats, shutdown_nvml
import atexit

# åˆå§‹åŒ–
init_nvml_once()

# æ³¨å†Œæ¸…ç†å‡½æ•°
atexit.register(shutdown_nvml)

# ä¾§è¾¹æ ç›‘æ§
with st.sidebar:
    st.subheader("GPU / VRAM Monitor")
    vram_box = st.empty()
    util_box = st.empty()
    
    # è·å–GPUçŠ¶æ€
    stats = get_gpu_stats()
    if stats:
        used_gb, total_gb, util_p, name = stats
        vram_box.metric("VRAM (GB)", f"{used_gb:.2f}/{total_gb:.2f}")
        util_box.caption(f"{name} | Util {util_p}%")
    else:
        vram_box.metric("VRAM (GB)", "N/A")
        util_box.caption("GPU not detected")
```

### 5.4 ä¼šè¯çŠ¶æ€ç®¡ç†

```python
import streamlit as st

# åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "user_name" not in st.session_state:
    st.session_state["user_name"] = "Guest"

# æ·»åŠ æ¶ˆæ¯
def add_message(role: str, content: str):
    st.session_state["messages"].append({
        "role": role,
        "content": content,
        "timestamp": time.time()
    })

# æ¸…ç©ºå†å²
if st.sidebar.button("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
    st.session_state["messages"] = []
    st.rerun()

# æ˜¾ç¤ºå†å²
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
```

### 5.5 æ—¥å¿—ç®¡ç†

```python
import json
from pathlib import Path

LOG_FILE = Path("backend/logs.jsonl")

def save_log(user_input: str, assistant_output: str, mode: str, total_sec: float):
    """ä¿å­˜å¯¹è¯æ—¥å¿—"""
    log = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "mode": mode,
        "user": user_input,
        "assistant": assistant_output,
        "total_time": round(total_sec, 3),
    }
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(log, ensure_ascii=False) + "\n")

def load_logs(limit: int = 20):
    """åŠ è½½æœ€æ–°Næ¡æ—¥å¿—"""
    if not LOG_FILE.exists():
        return []
    entries = []
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        for line in f:
            try:
                entries.append(json.loads(line))
            except:
                continue
    return entries[-limit:]

# æ˜¾ç¤ºå†å²å¯¹è¯
logs = load_logs(limit=5)
if logs:
    st.subheader("ğŸ—‚ éå»ã®ã‚„ã‚Šå–ã‚Š")
    for entry in logs:
        with st.chat_message("user"):
            st.markdown(entry.get("user", ""))
        with st.chat_message("assistant"):
            st.markdown(entry.get("assistant", ""))
```

---

## 6. å¸¸è§é—®é¢˜

### 6.1 å‰ç«¯æ— æ³•è®¿é—®

**ç—‡çŠ¶**: æµè§ˆå™¨æ˜¾ç¤º "æ— æ³•è®¿é—®æ­¤ç½‘ç«™"

**åŸå› **: Streamlitæœªå¯åŠ¨

**è§£å†³**:
```bash
# æ£€æŸ¥è¿›ç¨‹
ps aux | grep streamlit

# å¯åŠ¨Streamlit
streamlit run front-streaming/app.py
```

---

### 6.2 æ— æ³•è¿æ¥åç«¯

**ç—‡çŠ¶**: æ˜¾ç¤º "APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: Connection refused"

**åŸå› **: åç«¯APIæœªå¯åŠ¨

**è§£å†³**:
```bash
# æ£€æŸ¥åç«¯
curl http://localhost:8000/api/bot/respond

# å¯åŠ¨åç«¯
uvicorn backend.app:app --host 0.0.0.0 --port 8000
```

---

### 6.3 Streamingæ— å®æ—¶æ˜¾ç¤º

**ç—‡çŠ¶**: Streamingæ¨¡å¼åƒBlockingä¸€æ ·ç­‰å¾…å…¨éƒ¨å®Œæˆ

**åŸå› **: æœªä½¿ç”¨ `stream=True`

**è§£å†³**:
```python
# âŒ é”™è¯¯
response = requests.post(url, json=payload)

# âœ… æ­£ç¡®
with requests.post(url, json=payload, stream=True) as response:
    for chunk in response.iter_content():
        ...
```

---

### 6.4 GPUç›‘æ§æ˜¾ç¤ºN/A

**ç—‡çŠ¶**: VRAMæ˜¾ç¤º "N/A"

**åŸå› **: 
1. æœªå®‰è£…pynvml
2. ä¸æ˜¯NVIDIA GPU
3. NVMLåˆå§‹åŒ–å¤±è´¥

**è§£å†³**:
```bash
# å®‰è£…pynvml
pip install pynvml

# æ£€æŸ¥GPU
nvidia-smi

# æ£€æŸ¥Python
python -c "from pynvml import nvmlInit; nvmlInit(); print('OK')"
```

---

### 6.5 æ–‡ä»¶ä¸Šä¼ å¤±è´¥

**ç—‡çŠ¶**: ä¸Šä¼ åæ— ååº”æˆ–æŠ¥é”™

**åŸå› **: 
1. æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡maxUploadSizeï¼‰
2. æ–‡ä»¶ç±»å‹ä¸æ”¯æŒ
3. ChromaDBè¿æ¥å¤±è´¥

**è§£å†³**:
```toml
# .streamlit/config.toml
[server]
maxUploadSize = 200  # å¢åŠ åˆ°200MB
```

```python
# æ£€æŸ¥æ–‡ä»¶ç±»å‹
upload_file = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«",
    type=["txt", "pdf", "csv", "json"]  # ç¡®ä¿ç±»å‹åŒ¹é…
)
```

---

### 6.6 ä¼šè¯çŠ¶æ€ä¸¢å¤±

**ç—‡çŠ¶**: åˆ·æ–°é¡µé¢åå¯¹è¯å†å²æ¶ˆå¤±

**åŸå› **: Streamlitçš„session_stateä»…åœ¨ä¼šè¯å†…ä¿æŒ

**è§£å†³**:
```python
# ä¿å­˜åˆ°æ–‡ä»¶
if st.sidebar.button("ä¿å­˜å†å²"):
    with open("chat_history.json", "w") as f:
        json.dump(st.session_state["messages"], f)

# åŠ è½½å†å²
if st.sidebar.button("åŠ è½½å†å²"):
    with open("chat_history.json", "r") as f:
        st.session_state["messages"] = json.load(f)
```

---

### 6.7 é¡µé¢å¡é¡¿

**ç—‡çŠ¶**: è¾“å…¥åé¡µé¢å¡ä½

**åŸå› **: 
1. APIå“åº”æ…¢
2. æ¸²æŸ“å¤§é‡æ•°æ®
3. æœªè®¾ç½®timeout

**è§£å†³**:
```python
# 1. æ·»åŠ timeout
response = requests.post(url, json=payload, timeout=20)

# 2. ä½¿ç”¨spinner
with st.spinner("å‡¦ç†ä¸­..."):
    response = requests.post(...)

# 3. é™åˆ¶æ˜¾ç¤ºæ•°é‡
logs = load_logs(limit=5)  # ä»…æ˜¾ç¤º5æ¡
```

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 ç¼“å­˜æ•°æ®

```python
@st.cache_data(ttl=60)  # ç¼“å­˜60ç§’
def load_logs_cached(limit: int = 20):
    return load_logs(limit)

# ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬
logs = load_logs_cached(limit=5)
```

### 7.2 å»¶è¿ŸåŠ è½½

```python
# ä»…åœ¨å±•å¼€æ—¶åŠ è½½
with st.expander("æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"):
    files = list(KNOWLEDGE_DIR.glob("*"))
    for f in files:
        st.text(f.name)
```

### 7.3 å‡å°‘é‡æ–°è¿è¡Œ

```python
# ä½¿ç”¨formé¿å…æ¯æ¬¡è¾“å…¥éƒ½é‡æ–°è¿è¡Œ
with st.form("query_form"):
    user_input = st.text_input("è³ªå•")
    submitted = st.form_submit_button("é€ä¿¡")
    
    if submitted:
        # å¤„ç†æŸ¥è¯¢
        ...
```

### 7.4 åˆ†æ‰¹æ˜¾ç¤º

```python
# åˆ†æ‰¹æ˜¾ç¤ºé•¿å›ç­”
MAX_PREVIEW_LENGTH = 500

if len(reply) > MAX_PREVIEW_LENGTH:
    st.markdown(reply[:MAX_PREVIEW_LENGTH] + "...")
    with st.expander("å…¨æ–‡ã‚’è¡¨ç¤º"):
        st.markdown(reply)
else:
    st.markdown(reply)
```

---

## 8. è°ƒè¯•æŠ€å·§

### 8.1 æ˜¾ç¤ºSession State

```python
with st.sidebar.expander("Debug: Session State"):
    st.json(st.session_state)
```

### 8.2 æ˜¾ç¤ºAPIè¯·æ±‚è¯¦æƒ…

```python
with st.expander("Debug: API Request"):
    st.code(f"""
URL: {api_url}
Payload: {json.dumps({"prompt": user_input}, indent=2)}
Timeout: 20s
    """)
```

### 8.3 æ˜¾ç¤ºå“åº”è¯¦æƒ…

```python
with st.expander("Debug: API Response"):
    st.code(f"""
Status: {response.status_code}
Headers: {dict(response.headers)}
Body: {response.text[:500]}
    """)
```

### 8.4 æ€§èƒ½åˆ†æ

```python
import time

# è®¡æ—¶å™¨
start = time.perf_counter()

# ... æ“ä½œ ...

elapsed = time.perf_counter() - start
st.caption(f"â±ï¸ å‡¦ç†æ™‚é–“: {elapsed:.3f}s")
```

### 8.5 é”™è¯¯è¿½è¸ª

```python
try:
    response = requests.post(...)
except Exception as e:
    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
    with st.expander("è©³ç´°"):
        st.exception(e)  # æ˜¾ç¤ºå®Œæ•´å †æ ˆ
```

---

## 9. é«˜çº§ç”¨æ³•

### 9.1 å¤šé¡µé¢åº”ç”¨

åˆ›å»º `pages/` ç›®å½•ï¼š

```
front-streaming/
â”œâ”€â”€ app.py              # ä¸»é¡µ
â””â”€â”€ pages/
    â”œâ”€â”€ 1_ğŸ“Š_Analytics.py
    â”œâ”€â”€ 2_âš™ï¸_Settings.py
    â””â”€â”€ 3_ğŸ“_Files.py
```

Streamlitä¼šè‡ªåŠ¨è¯†åˆ«ä¸ºå¤šé¡µé¢åº”ç”¨ã€‚

### 9.2 è‡ªå®šä¹‰ä¸»é¢˜

```python
# åœ¨ä»£ç ä¸­è®¾ç½®
st.markdown("""
    <style>
    .stChatMessage {
        background-color: #f0f0f0;
        border-radius: 10px;
        padding: 10px;
    }
    </style>
""", unsafe_allow_html=True)
```

### 9.3 WebSocketæ”¯æŒï¼ˆå®éªŒæ€§ï¼‰

```python
# æ³¨æ„ï¼šStreamlitåŸç”Ÿä¸æ”¯æŒWebSocket
# å¯ä½¿ç”¨streamlit-javascript-callbackåº“
```

### 9.4 æ•°æ®å¯¼å‡º

```python
# å¯¼å‡ºå¯¹è¯å†å²ä¸ºCSV
import pandas as pd

if st.sidebar.button("Export CSV"):
    df = pd.DataFrame(st.session_state["messages"])
    csv = df.to_csv(index=False)
    st.download_button(
        "Download",
        csv,
        file_name="chat_history.csv",
        mime="text/csv"
    )
```

---

## 10. å¿«é€ŸæŸ¥è¯¢è¡¨

### 10.1 å¸¸ç”¨ç»„ä»¶

| ç»„ä»¶ | ç”¨é€” | ç¤ºä¾‹ |
|-----|------|------|
| `st.title()` | æ ‡é¢˜ | `st.title("æ ‡é¢˜")` |
| `st.markdown()` | Markdownæ–‡æœ¬ | `st.markdown("**ç²—ä½“**")` |
| `st.button()` | æŒ‰é’® | `if st.button("ç‚¹å‡»"):` |
| `st.text_input()` | æ–‡æœ¬è¾“å…¥ | `text = st.text_input("æ ‡ç­¾")` |
| `st.selectbox()` | ä¸‹æ‹‰é€‰æ‹© | `option = st.selectbox("é€‰æ‹©", [...])` |
| `st.slider()` | æ»‘å— | `val = st.slider("æ ‡ç­¾", 0, 100)` |
| `st.checkbox()` | å¤é€‰æ¡† | `if st.checkbox("é€‰é¡¹"):` |

### 10.2 å¸ƒå±€ç»„ä»¶

| ç»„ä»¶ | ç”¨é€” | ç¤ºä¾‹ |
|-----|------|------|
| `st.sidebar` | ä¾§è¾¹æ  | `with st.sidebar:` |
| `st.columns()` | åˆ—å¸ƒå±€ | `col1, col2 = st.columns(2)` |
| `st.expander()` | å¯æŠ˜å  | `with st.expander("æ ‡é¢˜"):` |
| `st.container()` | å®¹å™¨ | `with st.container():` |
| `st.empty()` | å ä½ç¬¦ | `placeholder = st.empty()` |

### 10.3 æ˜¾ç¤ºç»„ä»¶

| ç»„ä»¶ | ç”¨é€” | ç¤ºä¾‹ |
|-----|------|------|
| `st.success()` | æˆåŠŸæ¶ˆæ¯ | `st.success("æˆåŠŸ")` |
| `st.error()` | é”™è¯¯æ¶ˆæ¯ | `st.error("é”™è¯¯")` |
| `st.warning()` | è­¦å‘Šæ¶ˆæ¯ | `st.warning("è­¦å‘Š")` |
| `st.info()` | ä¿¡æ¯æ¶ˆæ¯ | `st.info("ä¿¡æ¯")` |
| `st.spinner()` | åŠ è½½åŠ¨ç”» | `with st.spinner("åŠ è½½ä¸­"):` |

### 10.4 æ•°æ®ç»„ä»¶

| ç»„ä»¶ | ç”¨é€” | ç¤ºä¾‹ |
|-----|------|------|
| `st.dataframe()` | æ•°æ®è¡¨ | `st.dataframe(df)` |
| `st.table()` | é™æ€è¡¨æ ¼ | `st.table(df)` |
| `st.metric()` | æŒ‡æ ‡å¡ç‰‡ | `st.metric("æ ‡ç­¾", "100")` |
| `st.json()` | JSONå±•ç¤º | `st.json({"key": "value"})` |
| `st.code()` | ä»£ç å— | `st.code("print('hello')")` |

---

## é™„å½•

### A. Streamlitå‘½ä»¤è¡Œå‚æ•°

```bash
streamlit run app.py \
  --server.port 8501 \
  --server.address 0.0.0.0 \
  --server.headless true \
  --browser.gatherUsageStats false \
  --server.fileWatcherType none  # ç”Ÿäº§æ¨¡å¼
```

### B. ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®ç«¯å£
export STREAMLIT_SERVER_PORT=8501

# ç¦ç”¨é¥æµ‹
export STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
```

### C. æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | å…¸å‹å€¼ | è¯´æ˜ |
|-----|-------|------|
| é¡µé¢åŠ è½½ | <1s | é¦–æ¬¡è®¿é—® |
| äº¤äº’å“åº” | <0.5s | ç‚¹å‡»æŒ‰é’® |
| Streaming TTFB | 0.5-2s | é¦–å­—èŠ‚ |
| Blocking Total | 3-8s | å®Œæ•´å“åº” |

### D. å¿«æ·é”®

| å¿«æ·é”® | åŠŸèƒ½ |
|-------|------|
| `R` | é‡æ–°è¿è¡Œåº”ç”¨ |
| `C` | æ¸…é™¤ç¼“å­˜ |
| `?` | æ˜¾ç¤ºå¿«æ·é”®å¸®åŠ© |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-02-01  
**ç»´æŠ¤è€…**: Kitaå¼€å‘å›¢é˜Ÿ

**ç›¸å…³æ–‡æ¡£**:
- è¯¦ç»†æ¶æ„: `FRONTEND_ARCHITECTURE.md`
- åç«¯API: `../backend/API_REFERENCE.md`
- RAGç³»ç»Ÿ: `../rag/RAG_DOCUMENTATION_INDEX.md`
