# å‰ç«¯æ¶æ„ä¸å®ç°æ–‡æ¡£

## æ–‡æ¡£æ¦‚è¿°
æœ¬æ–‡æ¡£è¯¦ç»†æè¿°Kitaç³»ç»Ÿå‰ç«¯WebUIçš„æ¶æ„è®¾è®¡ã€å®ç°ç»†èŠ‚ã€åŠŸèƒ½æ¨¡å—å’Œæœ€ä½³å®è·µã€‚å‰ç«¯åŸºäºStreamlitæ¡†æ¶ï¼Œæä¾›äº¤äº’å¼å¯¹è¯ç•Œé¢ã€å®æ—¶æ€§èƒ½ç›‘æ§å’ŒçŸ¥è¯†æ–‡ä»¶ç®¡ç†åŠŸèƒ½ã€‚

---

## ç›®å½•
1. [å‰ç«¯æ¦‚è¿°](#1-å‰ç«¯æ¦‚è¿°)
2. [æ¶æ„è®¾è®¡](#2-æ¶æ„è®¾è®¡)
3. [æ ¸å¿ƒåŠŸèƒ½æ¨¡å—](#3-æ ¸å¿ƒåŠŸèƒ½æ¨¡å—)
4. [UIç»„ä»¶è¯¦è§£](#4-uiç»„ä»¶è¯¦è§£)
5. [çŠ¶æ€ç®¡ç†](#5-çŠ¶æ€ç®¡ç†)
6. [APIé›†æˆ](#6-apié›†æˆ)
7. [GPUç›‘æ§ç³»ç»Ÿ](#7-gpuç›‘æ§ç³»ç»Ÿ)
8. [çŸ¥è¯†æ–‡ä»¶ç®¡ç†](#8-çŸ¥è¯†æ–‡ä»¶ç®¡ç†)
9. [æ—¥å¿—ç³»ç»Ÿ](#9-æ—¥å¿—ç³»ç»Ÿ)
10. [æ€§èƒ½ä¼˜åŒ–](#10-æ€§èƒ½ä¼˜åŒ–)
11. [ç”¨æˆ·ä½“éªŒ](#11-ç”¨æˆ·ä½“éªŒ)
12. [éƒ¨ç½²é…ç½®](#12-éƒ¨ç½²é…ç½®)

---

## 1. å‰ç«¯æ¦‚è¿°

### 1.1 æŠ€æœ¯æ ˆ

**æ ¸å¿ƒæ¡†æ¶**:
- **Streamlit**: Python Webåº”ç”¨æ¡†æ¶ï¼Œæ”¯æŒå¿«é€Ÿæ„å»ºæ•°æ®åº”ç”¨
- **Python 3.10+**: ç±»å‹æç¤ºã€å¼‚æ­¥æ”¯æŒ

**ä¾èµ–åº“**:
- **requests**: HTTPå®¢æˆ·ç«¯ï¼Œè°ƒç”¨åç«¯API
- **pynvml**: NVIDIA GPUç›‘æ§ï¼ˆå¯é€‰ï¼‰
- **json/pathlib**: æ•°æ®å¤„ç†å’Œæ–‡ä»¶ç®¡ç†

### 1.2 æ ¸å¿ƒèŒè´£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å‰ç«¯WebUIæ ¸å¿ƒèŒè´£                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. æä¾›ç”¨æˆ·äº¤äº’ç•Œé¢ï¼ˆå¯¹è¯æ¡†ã€æŒ‰é’®ï¼‰              â”‚
â”‚ 2. å®æ—¶å±•ç¤ºå¯¹è¯å†å²                              â”‚
â”‚ 3. è°ƒç”¨åç«¯APIè·å–å›ç­”                          â”‚
â”‚ 4. æ”¯æŒBlocking/Streamingä¸¤ç§æ¨¡å¼               â”‚
â”‚ 5. ç›‘æ§GPU/VRAMä½¿ç”¨æƒ…å†µ                         â”‚
â”‚ 6. ç®¡ç†çŸ¥è¯†æ–‡ä»¶ä¸Šä¼ å’Œæ£€ç´¢                        â”‚
â”‚ 7. å±•ç¤ºæ€§èƒ½æŒ‡æ ‡ï¼ˆTTFBã€Total Timeï¼‰             â”‚
â”‚ 8. æ˜¾ç¤ºå‚è€ƒä¿¡æ¯ï¼ˆReferencesï¼‰                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 æ–‡ä»¶ç»“æ„

```
front-streaming/
â”œâ”€â”€ app.py              # Streamlitä¸»åº”ç”¨
â”œâ”€â”€ gpu_stats.py        # GPUç›‘æ§æ¨¡å—
â”œâ”€â”€ area.jsonl          # ç”ºåæ•°æ®ï¼ˆåç«¯åŒæ­¥ï¼‰
â”œâ”€â”€ rag_docs_merged.jsonl  # åƒåœ¾åˆ†ç±»æ•°æ®ï¼ˆåç«¯åŒæ­¥ï¼‰
â””â”€â”€ __pycache__/        # Pythonç¼“å­˜
```

---

## 2. æ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ç”¨æˆ·æµè§ˆå™¨                              â”‚
â”‚                    (http://localhost:8501)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Streamlit åº”ç”¨å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  UI æ¸²æŸ“å±‚                                            â”‚   â”‚
â”‚  â”‚   - æ ‡é¢˜ã€ä¾§è¾¹æ ã€ä¸»å†…å®¹åŒº                           â”‚   â”‚
â”‚  â”‚   - Chatç»„ä»¶ï¼ˆç”¨æˆ·/åŠ©æ‰‹æ¶ˆæ¯ï¼‰                        â”‚   â”‚
â”‚  â”‚   - æŒ‡æ ‡å±•ç¤ºï¼ˆTTFBã€Total Timeï¼‰                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  äº¤äº’é€»è¾‘å±‚                                           â”‚   â”‚
â”‚  â”‚   - ç”¨æˆ·è¾“å…¥å¤„ç†                                     â”‚   â”‚
â”‚  â”‚   - æ¨¡å¼åˆ‡æ¢ï¼ˆBlocking/Streamingï¼‰                   â”‚   â”‚
â”‚  â”‚   - æ–‡ä»¶ä¸Šä¼ å¤„ç†                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  çŠ¶æ€ç®¡ç†å±‚                                           â”‚   â”‚
â”‚  â”‚   - st.session_stateï¼ˆå¯¹è¯å†å²ï¼‰                     â”‚   â”‚
â”‚  â”‚   - ä¸´æ—¶å˜é‡ï¼ˆæ€§èƒ½æŒ‡æ ‡ï¼‰                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  åç«¯APIå±‚ (FastAPI)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  - POST /api/bot/respond (Blocking)                  â”‚   â”‚
â”‚  â”‚  - POST /api/bot/respond_stream (Streaming)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RAG æ ¸å¿ƒ + ChromaDB                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ•°æ®æµ

#### 2.2.1 Blockingæ¨¡å¼æ•°æ®æµ

```
ç”¨æˆ·è¾“å…¥
    â†“
1. Streamlit æ¥æ”¶è¾“å…¥
    â†“
2. æ„å»ºè¯·æ±‚ JSON
    â†“
3. POST /api/bot/respond
    â†“
4. ç­‰å¾…å®Œæ•´å“åº”ï¼ˆé˜»å¡ï¼‰
    â†“
5. è§£æå“åº” JSON
    â”‚
    â”œâ”€ reply: æ˜¾ç¤ºå›ç­”
    â””â”€ references: æ˜¾ç¤ºå‚è€ƒä¿¡æ¯
    â†“
6. æ›´æ–° session_state
    â†“
7. è®°å½•æ—¥å¿—
```

#### 2.2.2 Streamingæ¨¡å¼æ•°æ®æµ

```
ç”¨æˆ·è¾“å…¥
    â†“
1. Streamlit æ¥æ”¶è¾“å…¥
    â†“
2. æ„å»ºè¯·æ±‚ JSON
    â†“
3. POST /api/bot/respond_stream
    â†“
4. å»ºç«‹æµè¿æ¥ï¼ˆstream=Trueï¼‰
    â†“
5. é€å—æ¥æ”¶æ–‡æœ¬
    â”‚
    â”œâ”€ ç¬¬1å—: è®°å½•TTFBï¼Œå®æ—¶æ˜¾ç¤º
    â”œâ”€ ç¬¬2å—: è¿½åŠ æ˜¾ç¤º
    â”œâ”€ ç¬¬3å—: è¿½åŠ æ˜¾ç¤º
    â””â”€ ...
    â†“
6. æµç»“æŸï¼Œè§£æ X-References
    â†“
7. æ˜¾ç¤ºå‚è€ƒä¿¡æ¯
    â†“
8. æ›´æ–° session_state
    â†“
9. è®°å½•æ—¥å¿—
```

### 2.3 å…³é”®è®¾è®¡æ¨¡å¼

#### 2.3.1 å•é¡µåº”ç”¨ï¼ˆSPAï¼‰æ¨¡å¼

Streamlitæœ¬è´¨æ˜¯å•é¡µåº”ç”¨ï¼Œæ¯æ¬¡äº¤äº’ä¼šé‡æ–°è¿è¡Œæ•´ä¸ªè„šæœ¬ï¼š

```python
# è„šæœ¬ä»å¤´å¼€å§‹æ‰§è¡Œ
st.set_page_config(...)

# åˆå§‹åŒ–ï¼ˆä»…é¦–æ¬¡ï¼‰
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# UIæ¸²æŸ“
st.title("...")
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).markdown(msg["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
user_input = st.chat_input("...")
if user_input:
    # å¤„ç†é€»è¾‘
    ...
```

**ç‰¹ç‚¹**:
- æ¯æ¬¡äº¤äº’éƒ½é‡æ–°è¿è¡Œè„šæœ¬
- ä½¿ç”¨ `st.session_state` ä¿æŒçŠ¶æ€
- ç®€å•ç›´è§‚ï¼Œæ— éœ€å¤æ‚è·¯ç”±

#### 2.3.2 çŠ¶æ€ç®¡ç†æ¨¡å¼

```python
# å…¨å±€çŠ¶æ€ï¼šå¯¹è¯å†å²
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# æ·»åŠ æ¶ˆæ¯
st.session_state["messages"].append({
    "role": "user",
    "content": user_input
})

# è¯»å–æ¶ˆæ¯
for msg in st.session_state["messages"]:
    display_message(msg)
```

#### 2.3.3 å“åº”å¼UIæ¨¡å¼

```python
# åˆ›å»ºå ä½ç¬¦
placeholder = st.empty()

# å®æ—¶æ›´æ–°
for chunk in stream:
    collected += chunk
    placeholder.markdown(collected)  # å®æ—¶åˆ·æ–°
```

---

## 3. æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### 3.1 åŠŸèƒ½æ¦‚è§ˆ

| æ¨¡å— | åŠŸèƒ½ | æ–‡ä»¶ |
|-----|------|------|
| å¯¹è¯ç•Œé¢ | ç”¨æˆ·è¾“å…¥ã€æ¶ˆæ¯å±•ç¤º | app.py |
| æ¨¡å¼åˆ‡æ¢ | Blocking/Streaming | app.py |
| GPUç›‘æ§ | VRAM/åˆ©ç”¨ç‡ | gpu_stats.py |
| æ–‡ä»¶ç®¡ç† | ä¸Šä¼ ã€åˆ—è¡¨ | app.py |
| æ—¥å¿—æŸ¥çœ‹ | å†å²å¯¹è¯ | app.py |
| æ€§èƒ½æŒ‡æ ‡ | TTFBã€Total Time | app.py |
| å‚è€ƒä¿¡æ¯ | Referenceså±•ç¤º | app.py |

### 3.2 æ¨¡å—ä¾èµ–å…³ç³»

```
app.py (ä¸»åº”ç”¨)
    â”‚
    â”œâ”€ import gpu_stats
    â”‚      â””â”€ get_gpu_stats()
    â”‚
    â”œâ”€ import rag.user_knowledge
    â”‚      â””â”€ add_file_to_chroma()
    â”‚
    â””â”€ import requests
           â””â”€ è°ƒç”¨åç«¯API
```

---

## 4. UIç»„ä»¶è¯¦è§£

### 4.1 é¡µé¢å¸ƒå±€

```python
st.set_page_config(
    page_title="Llama Chat (Streaming+Metrics)",
    page_icon="â±ï¸"
)

st.title("â±ï¸ Llama Chat â€“ Streaming & Metrics")

# ä¾§è¾¹æ 
with st.sidebar:
    # GPUç›‘æ§
    st.subheader("GPU / VRAM Monitor")
    vram_box = st.empty()
    util_box = st.empty()
    
    # æ¨¡å¼é€‰æ‹©
    mode = st.radio("å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["Blocking", "Streaming"])
    
    # æ–‡ä»¶ç®¡ç†
    st.subheader("ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†")
    upload_file = st.file_uploader("...")

# ä¸»å†…å®¹åŒº
# - å†å²å¯¹è¯å±•ç¤º
# - å®æ—¶å¯¹è¯åŒº
# - æ€§èƒ½æŒ‡æ ‡
```

**å¸ƒå±€ç‰¹ç‚¹**:
- å·¦ä¾§è¾¹æ ï¼šæ§åˆ¶å’Œç›‘æ§
- ä¸»å†…å®¹åŒºï¼šå¯¹è¯å†å²å’Œå®æ—¶äº¤äº’
- é¡¶éƒ¨æ ‡é¢˜ï¼šå“ç‰Œå’ŒåŠŸèƒ½æç¤º

### 4.2 å¯¹è¯ç»„ä»¶

#### 4.2.1 å†å²å¯¹è¯å±•ç¤º

```python
logs = load_logs(limit=5)
if logs:
    st.subheader("ğŸ—‚ éå»ã®ã‚„ã‚Šå–ã‚Šï¼ˆæœ€æ–°5ä»¶ï¼‰")
    for entry in logs:
        with st.chat_message("user"):
            st.markdown(entry.get("user", ""))
        with st.chat_message("assistant"):
            st.markdown(entry.get("assistant", ""))
    st.divider()
```

**åŠŸèƒ½**:
- ä» `backend/logs.jsonl` åŠ è½½æœ€æ–°5æ¡
- ä½¿ç”¨ `st.chat_message` ç»„ä»¶
- æä¾›å†å²ä¸Šä¸‹æ–‡

#### 4.2.2 å®æ—¶å¯¹è¯åŒº

```python
for m in st.session_state["messages"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if user_input:
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
    with st.chat_message("assistant"):
        placeholder = st.empty()
        # å®æ—¶æ›´æ–° placeholder
```

**ç‰¹ç‚¹**:
- `st.chat_message`: è‡ªåŠ¨æ·»åŠ å¤´åƒå’Œæ ·å¼
- `st.chat_input`: å›ºå®šåº•éƒ¨è¾“å…¥æ¡†
- `st.empty()`: å ä½ç¬¦ï¼Œæ”¯æŒå®æ—¶æ›´æ–°

### 4.3 æ€§èƒ½æŒ‡æ ‡ç»„ä»¶

```python
col1, col2, col3, col4 = st.columns(4)
ttfb_area   = col1.empty()
total_area  = col2.empty()
tokps_area  = col3.empty()
outtok_area = col4.empty()

# å®æ—¶æ›´æ–°
ttfb_area.metric("TTFB (s)", round(ttfb, 3))
total_area.metric("Total (s)", round(total_sec, 3))
tokps_area.metric("Tokens/sec", "-")
outtok_area.metric("Output tokens", "-")
```

**æŒ‡æ ‡è¯´æ˜**:
- **TTFB** (Time To First Byte): é¦–å­—èŠ‚è¿”å›æ—¶é—´
- **Total**: æ€»å“åº”æ—¶é—´
- **Tokens/sec**: æ¯ç§’ç”Ÿæˆtokenæ•°ï¼ˆæš‚æœªå®ç°ï¼‰
- **Output tokens**: è¾“å‡ºtokenæ€»æ•°ï¼ˆæš‚æœªå®ç°ï¼‰

### 4.4 å‚è€ƒä¿¡æ¯ç»„ä»¶

```python
if references:
    st.markdown("### ğŸ“‘ å‚è€ƒæƒ…å ±ï¼ˆä¸Šä½ãƒãƒ£ãƒ³ã‚¯ï¼‰")
    for ref in references:
        file = ref.get("file", "?")
        page = ref.get("page", "?")
        chunk = ref.get("chunk") or ref.get("chunk_id") or ref.get("id", "?")
        text = ref.get("text", "")[:200]
        
        st.markdown(
            f"- **{file} p.{page} (chunk {chunk})**\n"
            f"  \n> {text}..."
        )
```

**æ˜¾ç¤ºæ•ˆæœ**:
```
### ğŸ“‘ å‚è€ƒæƒ…å ±ï¼ˆä¸Šä½ãƒãƒ£ãƒ³ã‚¯ï¼‰
- **manual.pdf p.3 (chunk 1)**
  > ãƒ‘ã‚½ã‚³ãƒ³æœ¬ä½“ï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—å‹ãƒ»ãƒãƒ¼ãƒˆå‹ï¼‰ã¯ç²—å¤§ã”ã¿ã¨ã—ã¦...
```

### 4.5 ä¾§è¾¹æ ç»„ä»¶

#### 4.5.1 GPUç›‘æ§

```python
with st.sidebar:
    st.subheader("GPU / VRAM Monitor")
    vram_box = st.empty()
    util_box = st.empty()
    
    stats = get_gpu_stats()
    if stats:
        used_gb, total_gb, util_p, name = stats
        vram_box.metric("VRAM (GB)", f"{used_gb:.2f}/{total_gb:.2f}")
        util_box.caption(f"{name} | Util {util_p}%")
    else:
        vram_box.metric("VRAM (GB)", "N/A")
        util_box.caption("GPU not detected")
```

**æ˜¾ç¤ºæ•ˆæœ**:
```
GPU / VRAM Monitor
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VRAM (GB)        â”‚
â”‚ 4.23/8.00        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
NVIDIA GeForce RTX 3060 | Util 85%
```

#### 4.5.2 æ¨¡å¼é€‰æ‹©

```python
mode = st.radio(
    "å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
    ["Blocking", "Streaming"],
    horizontal=True,
    key="response_mode"
)
```

**UI**:
```
å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ
â—‰ Blocking    â—‹ Streaming
```

#### 4.5.3 æ–‡ä»¶ç®¡ç†

```python
st.subheader("ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†")

upload_file = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["txt", "pdf", "csv", "json"]
)

if upload_file is not None:
    save_path = KNOWLEDGE_DIR / upload_file.name
    with open(save_path, "wb") as f:
        f.write(upload_file.getbuffer())
    st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {upload_file.name}")
    
    # æ·»åŠ åˆ°ChromaDB
    add_file_to_chroma(save_path)

# æ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶
files = list(KNOWLEDGE_DIR.glob("*"))
if files:
    st.caption("æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:")
    for f in files:
        st.text(f.name)
```

---

## 5. çŠ¶æ€ç®¡ç†

### 5.1 Session State

Streamlitçš„ `st.session_state` æ˜¯è·¨è„šæœ¬è¿è¡Œä¿æŒçŠ¶æ€çš„æœºåˆ¶ã€‚

#### 5.1.1 å¯¹è¯å†å²

```python
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# æ·»åŠ æ¶ˆæ¯
st.session_state["messages"].append({
    "role": "user",
    "content": user_input
})

st.session_state["messages"].append({
    "role": "assistant",
    "content": collected
})

# è¯»å–æ¶ˆæ¯
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
```

**æ•°æ®ç»“æ„**:
```python
st.session_state["messages"] = [
    {"role": "user", "content": "ãƒãƒ¼ãƒˆPCã®æ¨ã¦æ–¹"},
    {"role": "assistant", "content": "ãƒãƒ¼ãƒˆPCã¯ç²—å¤§ã”ã¿ã¨ã—ã¦..."},
    {"role": "user", "content": "å…«å¹¡æ±åŒºã®åé›†æ—¥ã¯ï¼Ÿ"},
    {"role": "assistant", "content": "ç«æ›œæ—¥ã¨é‡‘æ›œæ—¥ã§ã™ã€‚"},
]
```

#### 5.1.2 æ¸…ç©ºå†å²

```python
# æ·»åŠ æ¸…ç©ºæŒ‰é’®
if st.sidebar.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
    st.session_state["messages"] = []
    st.rerun()
```

### 5.2 ä¸´æ—¶å˜é‡

éæŒä¹…åŒ–å˜é‡ï¼Œæ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶é‡æ–°åˆ›å»ºï¼š

```python
# æ€§èƒ½æŒ‡æ ‡
t_start = time.perf_counter()
ttfb = None
total_sec = None

# å“åº”å†…å®¹
collected = ""
references = []
```

---

## 6. APIé›†æˆ

### 6.1 Blockingæ¨¡å¼é›†æˆ

```python
if mode == "Blocking":
    try:
        api_url = "http://localhost:8000/api/bot/respond"
        res = requests.post(
            api_url,
            json={"prompt": user_input},
            timeout=20
        )
        res.raise_for_status()
        
        # è§£æå“åº”
        data = res.json()
        reply = data.get("reply", "")
        references = data.get("references", [])
        
    except Exception as e:
        reply = "APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: " + str(e)
        references = []
    
    # è®¡ç®—æ€»æ—¶é—´
    t_end = time.perf_counter()
    total_sec = t_end - t_start
    
    # æ›´æ–°æŒ‡æ ‡
    ttfb_area.metric("TTFB (s)", round(total_sec, 3))
    total_area.metric("Total (s)", round(total_sec, 3))
    
    # æ˜¾ç¤ºå›ç­”
    collected = reply
    placeholder.markdown(collected)
```

**å…³é”®ç‚¹**:
- `timeout=20`: é˜²æ­¢é•¿æ—¶é—´ç­‰å¾…
- `res.raise_for_status()`: è‡ªåŠ¨æŠ›å‡ºHTTPé”™è¯¯
- `data.get()`: å®‰å…¨è·å–å­—æ®µï¼Œé¿å…KeyError

### 6.2 Streamingæ¨¡å¼é›†æˆ

```python
if mode == "Streaming":
    try:
        api_url = "http://localhost:8000/api/bot/respond_stream"
        with requests.post(
            api_url,
            json={"prompt": user_input},
            stream=True,
            timeout=60
        ) as res:
            res.raise_for_status()
            
            ttfb = None
            collected = ""
            
            # é€å—æ¥æ”¶
            for chunk in res.iter_content(chunk_size=None):
                if not chunk:
                    continue
                
                # è®°å½•TTFB
                if ttfb is None:
                    ttfb = time.perf_counter()
                    ttfb_area.metric("TTFB (s)", round(ttfb - t_start, 3))
                
                # å®æ—¶æ˜¾ç¤º
                text = chunk.decode("utf-8")
                collected += text
                placeholder.markdown(collected)
            
            # è®¡ç®—æ€»æ—¶é—´
            t_end = time.perf_counter()
            total_sec = t_end - t_start
            total_area.metric("Total (s)", round(total_sec, 3))
            
            # è§£æReferencesï¼ˆåœ¨HTTP Headerä¸­ï¼‰
            references = []
            if "X-References" in res.headers:
                try:
                    references = json.loads(res.headers["X-References"])
                except Exception:
                    references = []
            
            # æ˜¾ç¤ºå‚è€ƒä¿¡æ¯
            if references:
                st.markdown("#### ğŸ“‘ å‚è€ƒæƒ…å ±")
                for ref in references:
                    st.markdown(
                        f"- **{ref.get('file','?')} p.{ref.get('page','?')} "
                        f"(chunk {ref.get('chunk','?')})**\n"
                        f"  \n> {ref.get('text','')[:200]}..."
                    )
    
    except Exception as e:
        collected = "APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: " + str(e)
        placeholder.markdown(collected)
```

**å…³é”®ç‚¹**:
- `stream=True`: å¯ç”¨æµå¼æ¥æ”¶
- `with ... as res`: è‡ªåŠ¨å…³é—­è¿æ¥
- `iter_content(chunk_size=None)`: é€å—è¿­ä»£
- `X-References`: ä»Headerè·å–å‚è€ƒä¿¡æ¯

### 6.3 é”™è¯¯å¤„ç†

```python
try:
    res = requests.post(api_url, json={"prompt": user_input}, timeout=20)
    res.raise_for_status()
    # ...
except requests.exceptions.Timeout:
    collected = "â±ï¸ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
except requests.exceptions.ConnectionError:
    collected = "âŒ ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
except requests.exceptions.HTTPError as e:
    collected = f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code}"
except Exception as e:
    collected = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"

placeholder.markdown(collected)
```

---

## 7. GPUç›‘æ§ç³»ç»Ÿ

### 7.1 gpu_stats.py æ¨¡å—

#### 7.1.1 NVMLæ–¹å¼ï¼ˆé¦–é€‰ï¼‰

```python
try:
    from pynvml import (
        nvmlInit, nvmlShutdown, nvmlDeviceGetHandleByIndex,
        nvmlDeviceGetMemoryInfo, nvmlDeviceGetUtilizationRates,
        nvmlDeviceGetName, nvmlDeviceGetCount
    )
    _NVML_AVAILABLE = True
except Exception:
    _NVML_AVAILABLE = False

def _nvml_get() -> Optional[Tuple[float, float, int, str]]:
    """è¿”å› (used_GB, total_GB, util_percent, gpu_name)"""
    if not _NVML_AVAILABLE:
        return None
    try:
        count = nvmlDeviceGetCount()
        if count == 0:
            return None
        
        handle = nvmlDeviceGetHandleByIndex(0)  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
        mem_info = nvmlDeviceGetMemoryInfo(handle)
        util_rates = nvmlDeviceGetUtilizationRates(handle)
        name = nvmlDeviceGetName(handle)
        
        used_gb = mem_info.used / (1024 ** 3)
        total_gb = mem_info.total / (1024 ** 3)
        util_percent = util_rates.gpu
        
        return (used_gb, total_gb, util_percent, name)
    except Exception:
        return None
```

**ä¼˜ç‚¹**:
- é€Ÿåº¦å¿«ï¼ˆ~1msï¼‰
- å‡†ç¡®
- ä½CPUå ç”¨

#### 7.1.2 nvidia-smiæ–¹å¼ï¼ˆå¤‡ç”¨ï¼‰

```python
def _nvidia_smi_get() -> Optional[Tuple[float, float, int, str]]:
    """ä½¿ç”¨nvidia-smiå‘½ä»¤è·å–GPUä¿¡æ¯"""
    if not shutil.which("nvidia-smi"):
        return None
    
    try:
        output = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=memory.used,memory.total,utilization.gpu,name",
             "--format=csv,noheader,nounits"],
            text=True
        )
        parts = output.strip().split(",")
        used_mb = float(parts[0].strip())
        total_mb = float(parts[1].strip())
        util_p = int(parts[2].strip())
        name = parts[3].strip()
        
        return (used_mb / 1024, total_mb / 1024, util_p, name)
    except Exception:
        return None
```

**ç¼ºç‚¹**:
- é€Ÿåº¦æ…¢ï¼ˆ~100msï¼‰
- CPUå ç”¨é«˜

#### 7.1.3 rocm-smiæ–¹å¼ï¼ˆAMD GPUï¼‰

```python
def _rocm_smi_get() -> Optional[Tuple[float, float, int, str]]:
    """æ”¯æŒAMD GPU"""
    if not shutil.which("rocm-smi"):
        return None
    # å®ç°ç»†èŠ‚...
```

### 7.2 åˆå§‹åŒ–å’Œæ¸…ç†

```python
# åº”ç”¨å¯åŠ¨æ—¶
init_nvml_once()

# åº”ç”¨ç»“æŸæ—¶
import atexit
atexit.register(shutdown_nvml)
```

### 7.3 å®æ—¶æ›´æ–°

```python
# åœ¨ä¾§è¾¹æ åˆ›å»ºå ä½ç¬¦
vram_box = st.empty()
util_box = st.empty()

# æŸ¥è¯¢GPUçŠ¶æ€
stats = get_gpu_stats()
if stats:
    used_gb, total_gb, util_p, name = stats
    vram_box.metric("VRAM (GB)", f"{used_gb:.2f}/{total_gb:.2f}")
    util_box.caption(f"{name} | Util {util_p}%")
else:
    vram_box.metric("VRAM (GB)", "N/A")
    util_box.caption("GPU not detected")
```

---

## 8. çŸ¥è¯†æ–‡ä»¶ç®¡ç†

### 8.1 æ–‡ä»¶ä¸Šä¼ 

```python
KNOWLEDGE_DIR = Path("knowledge_files")
KNOWLEDGE_DIR.mkdir(exist_ok=True)

upload_file = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["txt", "pdf", "csv", "json"]
)

if upload_file is not None:
    # ä¿å­˜æ–‡ä»¶
    save_path = KNOWLEDGE_DIR / upload_file.name
    with open(save_path, "wb") as f:
        f.write(upload_file.getbuffer())
    
    st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {upload_file.name}")
    
    # æ·»åŠ åˆ°ChromaDB
    add_file_to_chroma(save_path)
```

**æµç¨‹**:
1. ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
2. ä¿å­˜åˆ° `knowledge_files/` ç›®å½•
3. è°ƒç”¨ `add_file_to_chroma()` æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
4. æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯

### 8.2 æ–‡ä»¶åˆ—è¡¨

```python
files = list(KNOWLEDGE_DIR.glob("*"))
if files:
    st.caption("æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:")
    for f in files:
        st.text(f.name)
else:
    st.caption("ã¾ã ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
```

**æ˜¾ç¤ºæ•ˆæœ**:
```
æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:
manual.pdf
guide.txt
rules.csv
```

### 8.3 é›†æˆ user_knowledge æ¨¡å—

```python
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from rag.user_knowledge import add_file_to_chroma

# ä½¿ç”¨
add_file_to_chroma(save_path)
```

**åŠŸèƒ½**:
- è‡ªåŠ¨åˆ†å—ï¼ˆPDF/TXT/CSV/JSONï¼‰
- æ·»åŠ åˆ° `knowledge` collection
- æ”¯æŒåç»­RAGæ£€ç´¢

---

## 9. æ—¥å¿—ç³»ç»Ÿ

### 9.1 æ—¥å¿—è®°å½•

```python
LOG_FILE = Path("backend/logs.jsonl")

def save_log(user_input: str, assistant_output: str, mode: str, total_sec: float):
    log = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "mode": mode,
        "user": user_input,
        "assistant": assistant_output,
        "total_time": round(total_sec, 3),
    }
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(log, ensure_ascii=False) + "\n")
```

**è°ƒç”¨æ—¶æœº**:
```python
if total_sec is not None:
    save_log(user_input, collected, mode, total_sec)
```

### 9.2 æ—¥å¿—åŠ è½½

```python
def load_logs(limit: int = 20):
    if not LOG_FILE.exists():
        return []
    entries = []
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        for line in f:
            try:
                entries.append(json.loads(line))
            except Exception:
                continue
    return entries[-limit:]  # è¿”å›æœ€æ–°Næ¡
```

### 9.3 å†å²å¯¹è¯å±•ç¤º

```python
logs = load_logs(limit=5)
if logs:
    st.subheader("ğŸ—‚ éå»ã®ã‚„ã‚Šå–ã‚Šï¼ˆæœ€æ–°5ä»¶ï¼‰")
    for entry in logs:
        with st.chat_message("user"):
            st.markdown(entry.get("user", ""))
        with st.chat_message("assistant"):
            st.markdown(entry.get("assistant", ""))
    st.divider()
```

---

## 10. æ€§èƒ½ä¼˜åŒ–

### 10.1 é¿å…é‡å¤è®¡ç®—

```python
# âŒ æ¯æ¬¡éƒ½é‡æ–°åŠ è½½
logs = load_logs(limit=5)

# âœ… ä½¿ç”¨ç¼“å­˜ï¼ˆå¦‚æœæ—¥å¿—ä¸å¸¸æ›´æ–°ï¼‰
@st.cache_data(ttl=60)  # ç¼“å­˜60ç§’
def load_logs_cached(limit: int = 20):
    return load_logs(limit)
```

### 10.2 å»¶è¿ŸåŠ è½½

```python
# âŒ å¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰æ–‡ä»¶
files = list(KNOWLEDGE_DIR.glob("*"))

# âœ… ä»…åœ¨å±•å¼€æ—¶åŠ è½½
with st.expander("æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"):
    files = list(KNOWLEDGE_DIR.glob("*"))
    for f in files:
        st.text(f.name)
```

### 10.3 æµå¼æ˜¾ç¤ºä¼˜åŒ–

```python
# å‡å°‘åˆ·æ–°é¢‘ç‡
buffer = ""
for i, chunk in enumerate(res.iter_content(chunk_size=None)):
    buffer += chunk.decode("utf-8")
    
    # æ¯5å—æ›´æ–°ä¸€æ¬¡ï¼ˆå‡å°‘æ¸²æŸ“å¼€é”€ï¼‰
    if i % 5 == 0:
        placeholder.markdown(buffer)

# æœ€ç»ˆæ›´æ–°
placeholder.markdown(buffer)
```

### 10.4 GPUç›‘æ§é¢‘ç‡

```python
# ä»…åœ¨å¯¹è¯åæ›´æ–°GPUçŠ¶æ€ï¼ˆé¿å…é¢‘ç¹æŸ¥è¯¢ï¼‰
if user_input:
    # ... å¤„ç†å¯¹è¯ ...
    
    # æ›´æ–°GPUçŠ¶æ€
    stats = get_gpu_stats()
    if stats:
        vram_box.metric(...)
```

---

## 11. ç”¨æˆ·ä½“éªŒ

### 11.1 åŠ è½½çŠ¶æ€

```python
with st.spinner("ç”Ÿæˆä¸­..."):
    # APIè°ƒç”¨
    res = requests.post(...)
```

### 11.2 é”™è¯¯æç¤º

```python
if error:
    st.error("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: " + str(error))

# æˆ–ä½¿ç”¨emojiå¢å¼ºè§†è§‰æ•ˆæœ
st.warning("âš ï¸ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚")
st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
st.info("â„¹ï¸ Streaming ãƒ¢ãƒ¼ãƒ‰ã¯å®Ÿæ™‚é–“ã§å¿œç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
```

### 11.3 è¿›åº¦åé¦ˆ

```python
# Streamingæ¨¡å¼è‡ªåŠ¨æä¾›å®æ—¶åé¦ˆ
# å¯æ·»åŠ å­—ç¬¦è®¡æ•°
st.caption(f"ç”Ÿæˆæ¸ˆã¿: {len(collected)} æ–‡å­—")
```

### 11.4 å¿«æ·æ“ä½œ

```python
# ç¤ºä¾‹æŸ¥è¯¢æŒ‰é’®
col1, col2, col3 = st.columns(3)
with col1:
    if st.button("ãƒãƒ¼ãƒˆPCã®æ¨ã¦æ–¹"):
        st.session_state["quick_query"] = "ãƒãƒ¼ãƒˆPCã®æ¨ã¦æ–¹"
with col2:
    if st.button("å…«å¹¡æ±åŒºã®åé›†æ—¥"):
        st.session_state["quick_query"] = "å…«å¹¡æ±åŒºã®åé›†æ—¥"

# å¤„ç†å¿«æ·æŸ¥è¯¢
if "quick_query" in st.session_state:
    user_input = st.session_state["quick_query"]
    del st.session_state["quick_query"]
    # å¤„ç†æŸ¥è¯¢...
```

---

## 12. éƒ¨ç½²é…ç½®

### 12.1 Streamlité…ç½®

åˆ›å»º `.streamlit/config.toml`:

```toml
[server]
port = 8501
address = "0.0.0.0"
maxUploadSize = 200  # MB

[theme]
primaryColor = "#F63366"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"

[browser]
gatherUsageStats = false
```

### 12.2 å¯åŠ¨å‘½ä»¤

```bash
# å¼€å‘æ¨¡å¼
streamlit run front-streaming/app.py

# æŒ‡å®šç«¯å£
streamlit run front-streaming/app.py --server.port 8501

# ç”Ÿäº§æ¨¡å¼ï¼ˆç¦ç”¨æ–‡ä»¶ç›‘æ§ï¼‰
streamlit run front-streaming/app.py --server.fileWatcherType none
```

### 12.3 Dockeréƒ¨ç½²

**Dockerfile**:
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY pyproject.toml .
RUN pip install uv && uv sync

# å¤åˆ¶ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8501

# å¯åŠ¨å‘½ä»¤
CMD ["streamlit", "run", "front-streaming/app.py", "--server.address", "0.0.0.0"]
```

### 12.4 Nginxåå‘ä»£ç†

```nginx
server {
    listen 80;
    server_name kita.example.com;
    
    location / {
        proxy_pass http://localhost:8501;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

---

## 13. è°ƒè¯•æŠ€å·§

### 13.1 æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯

```python
# æ˜¾ç¤ºsession_state
with st.expander("Debug: Session State"):
    st.json(st.session_state)

# æ˜¾ç¤ºè¯·æ±‚è¯¦æƒ…
with st.expander("Debug: API Request"):
    st.code(f"URL: {api_url}\nPayload: {json.dumps({'prompt': user_input})}")
```

### 13.2 æ—¥å¿—è¾“å‡º

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

logger.debug(f"ç”¨æˆ·è¾“å…¥: {user_input}")
logger.debug(f"APIå“åº”: {res.status_code}")
```

### 13.3 æ€§èƒ½åˆ†æ

```python
import time

start = time.perf_counter()
# ... æ“ä½œ ...
elapsed = time.perf_counter() - start
st.caption(f"â±ï¸ å¤„ç†è€—æ—¶: {elapsed:.3f}s")
```

---

## 14. æ‰©å±•åŠŸèƒ½

### 14.1 å¯¹è¯å¯¼å‡º

```python
if st.sidebar.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
    chat_json = json.dumps(st.session_state["messages"], ensure_ascii=False, indent=2)
    st.download_button(
        "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        chat_json,
        file_name="chat_history.json",
        mime="application/json"
    )
```

### 14.2 ä¸»é¢˜åˆ‡æ¢

```python
theme = st.sidebar.selectbox("ãƒ†ãƒ¼ãƒ", ["ãƒ©ã‚¤ãƒˆ", "ãƒ€ãƒ¼ã‚¯"])
if theme == "ãƒ€ãƒ¼ã‚¯":
    st.markdown("""
        <style>
        .stApp {
            background-color: #1E1E1E;
            color: #FFFFFF;
        }
        </style>
    """, unsafe_allow_html=True)
```

### 14.3 å¤šè¯­è¨€æ”¯æŒ

```python
lang = st.sidebar.selectbox("Language", ["æ—¥æœ¬èª", "English", "ä¸­æ–‡"])

TRANSLATIONS = {
    "æ—¥æœ¬èª": {"title": "Llama ãƒãƒ£ãƒƒãƒˆ", "input": "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›"},
    "English": {"title": "Llama Chat", "input": "Enter message"},
    "ä¸­æ–‡": {"title": "Llama å¯¹è¯", "input": "è¾“å…¥æ¶ˆæ¯"},
}

st.title(TRANSLATIONS[lang]["title"])
user_input = st.chat_input(TRANSLATIONS[lang]["input"])
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-02-01  
**ç»´æŠ¤è€…**: Kitaå¼€å‘å›¢é˜Ÿ

**ç›¸å…³æ–‡æ¡£**:
- å¿«é€Ÿå‚è€ƒ: `FRONTEND_REFERENCE.md`
- åç«¯æ–‡æ¡£: `../backend/BACKEND_ARCHITECTURE.md`
- RAGç³»ç»Ÿ: `../rag/RAG_DOCUMENTATION_INDEX.md`
