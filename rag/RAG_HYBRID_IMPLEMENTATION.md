# Hybridå“åæŒ‡ç§°ç³»ç»Ÿ - è¯¦ç»†å¼€å‘å®æ–½æ–‡æ¡£

## æ–‡æ¡£ä¿¡æ¯
- **ç‰ˆæœ¬**: v1.0
- **æ—¥æœŸ**: 2026-02-01
- **çŠ¶æ€**: å¼€å‘æŒ‡å—
- **è´Ÿè´£äºº**: å¼€å‘å›¢é˜Ÿ

---

## ç›®å½•
1. [å®æ–½æ¦‚è¿°](#1-å®æ–½æ¦‚è¿°)
2. [å¼€å‘ç¯å¢ƒå‡†å¤‡](#2-å¼€å‘ç¯å¢ƒå‡†å¤‡)
3. [æ ¸å¿ƒæ¨¡å—å®ç°](#3-æ ¸å¿ƒæ¨¡å—å®ç°)
4. [é›†æˆä¸æµ‹è¯•](#4-é›†æˆä¸æµ‹è¯•)
5. [æ€§èƒ½ä¼˜åŒ–](#5-æ€§èƒ½ä¼˜åŒ–)
6. [éƒ¨ç½²ä¸ç›‘æ§](#6-éƒ¨ç½²ä¸ç›‘æ§)
7. [æ•…éšœæ’æŸ¥](#7-æ•…éšœæ’æŸ¥)

---

## 1. å®æ–½æ¦‚è¿°

### 1.1 å®æ–½ç›®æ ‡
åœ¨ç°æœ‰RAGç³»ç»Ÿä¸­ï¼Œå°†åŸºäºMeCabçš„å“åæŠ½å–é€»è¾‘æ›¿æ¢ä¸ºHybridåŒè·¯å¾„æ–¹æ¡ˆï¼Œæå‡å“åè¯†åˆ«å‡†ç¡®ç‡ä»70-80%è‡³85-95%ã€‚

### 1.2 å®æ–½èŒƒå›´

**ä¿®æ”¹çš„æ–‡ä»¶**ï¼š
- `rag/rag_demo3.py` - æ·»åŠ Hybridå“åè¯†åˆ«æ¨¡å—
- `backend/app.py` - å¯é€‰ï¼šæ·»åŠ æ€§èƒ½ç›‘æ§

**æ–°å¢çš„æ–‡ä»¶**ï¼š
- `rag/hybrid_grounding.py` - æ ¸å¿ƒå®ç°
- `rag/test_hybrid.py` - å•å…ƒæµ‹è¯•
- `rag/benchmark_hybrid.py` - æ€§èƒ½åŸºå‡†æµ‹è¯•

**ä¸ä¿®æ”¹çš„éƒ¨åˆ†**ï¼š
- ChromaDB collectionç»“æ„
- APIæ¥å£å®šä¹‰ï¼ˆschemas.pyï¼‰
- å‰ç«¯WebUI
- ç”ºåå¤„ç†é€»è¾‘

### 1.3 å®æ–½æ—¶é—´è¡¨

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | äº¤ä»˜ç‰© |
|-----|------|---------|--------|
| Phase 1 | è·¯å¾„Aå®ç°ä¸éªŒè¯ | 2å¤© | `path_a_baseline()` |
| Phase 2 | è·¯å¾„Bå®ç°ä¸é›†æˆ | 3å¤© | `path_b_llm_filter()` |
| Phase 3 | åˆå¹¶é€»è¾‘ä¸ä¼˜åŒ– | 2å¤© | `merge_candidates()` |
| Phase 4 | é›†æˆæµ‹è¯•ä¸è°ƒä¼˜ | 2å¤© | æµ‹è¯•æŠ¥å‘Š |
| Phase 5 | ç”Ÿäº§éƒ¨ç½²ä¸ç›‘æ§ | 1å¤© | éƒ¨ç½²æ–‡æ¡£ |

**æ€»è®¡**: 10å·¥ä½œæ—¥ï¼ˆ2å‘¨ï¼‰

---

## 2. å¼€å‘ç¯å¢ƒå‡†å¤‡

### 2.1 ä¾èµ–æ£€æŸ¥

ç¡®è®¤ä»¥ä¸‹ç»„ä»¶å·²å®‰è£…å¹¶è¿è¡Œï¼š

```bash
# æ£€æŸ¥OllamaæœåŠ¡
ollama list

# åº”åŒ…å«ä»¥ä¸‹æ¨¡å‹ï¼š
# - swallow:latest (LLM)
# - kun432/cl-nagoya-ruri-large:337m (Embedding)

# æ£€æŸ¥ChromaDB
python -c "import chromadb; print('ChromaDB OK')"

# æ£€æŸ¥MeCabï¼ˆä¿ç•™ç”¨äºé™çº§ï¼‰
python -c "import MeCab; print('MeCab OK')"
```

### 2.2 æµ‹è¯•æ•°æ®å‡†å¤‡

åˆ›å»ºæµ‹è¯•æ•°æ®é›† `rag/test_inputs.json`ï¼š

```json
{
  "short_inputs": [
    "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’æ¨ã¦ãŸã„",
    "å†·è”µåº«",
    "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯è£½ã®åç´ç®±"
  ],
  "long_inputs": [
    "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨å¤ã„ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã€ãã‚Œã‹ã‚‰å£Šã‚ŒãŸé›»å­ãƒ¬ãƒ³ã‚¸ã‚’å‡¦åˆ†ã—ãŸã„ã®ã§ã™ãŒã€ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ",
    "å­ä¾›ãŒå¤§ãããªã£ãŸã®ã§ã€ãƒ™ãƒ“ãƒ¼ã‚«ãƒ¼ã‚„ãƒ™ãƒ“ãƒ¼ãƒ™ãƒƒãƒ‰ã€ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆãªã©ã®è‚²å…ç”¨å“ã‚’ã¾ã¨ã‚ã¦æ¨ã¦ãŸã„ã§ã™ã€‚"
  ],
  "ambiguous_inputs": [
    "ãƒ‘ã‚½ã‚³ãƒ³é–¢é€£ã®æ©Ÿå™¨",
    "å®¶é›»è£½å“"
  ]
}
```

---

## 3. æ ¸å¿ƒæ¨¡å—å®ç°

### 3.1 åˆ›å»ºæ ¸å¿ƒæ¨¡å—æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `rag/hybrid_grounding.py`

```python
#!/usr/bin/env python3
"""
Hybridå“åæŒ‡ç§°æ¨¡å—
å®ç°åŒè·¯å¾„å“åå€™é€‰ç”Ÿæˆï¼šè·¯å¾„Aï¼ˆæ•´ä½“Embeddingï¼‰+ è·¯å¾„Bï¼ˆLLMè¿‡æ»¤ï¼‰
"""

import json
from typing import List, Dict, Tuple, Optional
import ollama
import chromadb
from dataclasses import dataclass
import time


# ========== æ•°æ®ç»“æ„å®šä¹‰ ==========

@dataclass
class Candidate:
    """å“åå€™é€‰ç»“æ„"""
    item_name: str          # å“å
    similarity: float       # ç›¸ä¼¼åº¦åˆ†æ•°
    source: str            # æ¥æºè·¯å¾„ ("path_a" | "path_b")
    metadata: Dict         # åŸå§‹metadataï¼ˆå‡ºã—æ–¹ã€å‚™è€ƒç­‰ï¼‰
    

@dataclass
class GroundingResult:
    """æŒ‡ç§°ç»“æœ"""
    candidates: List[Candidate]     # å€™é€‰åˆ—è¡¨ï¼ˆæŒ‰ç½®ä¿¡åº¦æ’åºï¼‰
    primary_candidate: Optional[Candidate]  # ä¸»å€™é€‰ï¼ˆç½®ä¿¡åº¦æœ€é«˜ï¼‰
    is_ambiguous: bool             # æ˜¯å¦å­˜åœ¨æ­§ä¹‰
    confidence_level: str          # ç½®ä¿¡åº¦çº§åˆ« ("high" | "medium" | "low")
    execution_time_ms: float       # æ‰§è¡Œè€—æ—¶
    path_used: str                # ä½¿ç”¨çš„è·¯å¾„ ("both" | "path_a_only" | "degraded")


# ========== é…ç½®å¸¸é‡ ==========

class HybridConfig:
    """Hybridç³»ç»Ÿé…ç½®"""
    
    # è·¯å¾„Aå‚æ•°
    PATH_A_TOP_K = 3
    
    # è·¯å¾„Bå‚æ•°
    PATH_B_MAX_CANDIDATES = 5
    PATH_B_TOP_K = 3
    PATH_B_TIMEOUT = 5  # ç§’
    
    # å¿«é€Ÿè·¯å¾„é˜ˆå€¼
    SHORT_INPUT_THRESHOLD = 20  # å­—ç¬¦æ•°
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    CONFIDENCE_THRESHOLD_HIGH = 0.45   # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
    CONFIDENCE_THRESHOLD_LOW = 0.30    # ä½ç½®ä¿¡åº¦é˜ˆå€¼
    AMBIGUITY_THRESHOLD = 0.05         # æ­§ä¹‰åˆ¤å®šé˜ˆå€¼ï¼ˆTop1ä¸Top2å·®å€¼ï¼‰
    
    # LLMé…ç½®
    LLM_MODEL = "swallow:latest"
    LLM_TEMPERATURE = 0.1  # ä½æ¸©åº¦ä»¥æé«˜ç¨³å®šæ€§


# ========== è·¯å¾„Aï¼šæ•´ä½“EmbeddingæŒ‡ç§° ==========

def path_a_global_embedding(
    user_input: str,
    gomi_collection: chromadb.Collection,
    top_k: int = HybridConfig.PATH_A_TOP_K
) -> List[Candidate]:
    """
    è·¯å¾„Aï¼šå¯¹ç”¨æˆ·è¾“å…¥å…¨æ–‡è¿›è¡ŒEmbeddingï¼Œç›´æ¥åŒ¹é…åƒåœ¾å“å
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        gomi_collection: ChromaDBåƒåœ¾åˆ†ç±»collection
        top_k: è¿”å›çš„å€™é€‰æ•°é‡
        
    Returns:
        å€™é€‰åˆ—è¡¨ï¼ˆCandidateå¯¹è±¡ï¼‰
    """
    try:
        results = gomi_collection.query(
            query_texts=[user_input],
            n_results=top_k
        )
        
        candidates = []
        if results and results["metadatas"] and results["distances"]:
            for meta, distance in zip(results["metadatas"][0], results["distances"][0]):
                # ChromaDBè¿”å›çš„æ˜¯è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦ (similarity = 1 - distance)
                similarity = 1.0 - distance
                
                candidates.append(Candidate(
                    item_name=meta.get("å“å", ""),
                    similarity=similarity,
                    source="path_a",
                    metadata=meta
                ))
        
        return candidates
        
    except Exception as e:
        print(f"âš ï¸ è·¯å¾„Aæ‰§è¡Œå¤±è´¥: {e}")
        return []


# ========== è·¯å¾„Bï¼šLLMå€™é€‰è¿‡æ»¤ ==========

def path_b_llm_filter(
    user_input: str,
    gomi_collection: chromadb.Collection,
    max_candidates: int = HybridConfig.PATH_B_MAX_CANDIDATES,
    top_k: int = HybridConfig.PATH_B_TOP_K
) -> List[Candidate]:
    """
    è·¯å¾„Bï¼šä½¿ç”¨LLMä»è¾“å…¥ä¸­æå–å¯èƒ½çš„åƒåœ¾å“åçŸ­è¯­ï¼Œç„¶ååˆ†åˆ«EmbeddingåŒ¹é…
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        gomi_collection: ChromaDBåƒåœ¾åˆ†ç±»collection
        max_candidates: LLMæœ€å¤šæå–çš„å€™é€‰çŸ­è¯­æ•°
        top_k: æ¯ä¸ªå€™é€‰çŸ­è¯­åŒ¹é…çš„Top-Kæ•°é‡
        
    Returns:
        å€™é€‰åˆ—è¡¨ï¼ˆCandidateå¯¹è±¡ï¼‰
    """
    try:
        # Step 1: LLMæå–å€™é€‰çŸ­è¯­
        extracted_phrases = _extract_phrases_with_llm(user_input, max_candidates)
        
        if not extracted_phrases:
            return []
        
        # Step 2: å¯¹æ¯ä¸ªå€™é€‰çŸ­è¯­è¿›è¡ŒEmbeddingåŒ¹é…
        all_candidates = []
        
        for phrase in extracted_phrases:
            results = gomi_collection.query(
                query_texts=[phrase],
                n_results=top_k
            )
            
            if results and results["metadatas"] and results["distances"]:
                for meta, distance in zip(results["metadatas"][0], results["distances"][0]):
                    similarity = 1.0 - distance
                    
                    all_candidates.append(Candidate(
                        item_name=meta.get("å“å", ""),
                        similarity=similarity,
                        source=f"path_b:{phrase}",  # è®°å½•æ¥æºçŸ­è¯­
                        metadata=meta
                    ))
        
        # Step 3: å»é‡å¹¶æ’åº
        unique_candidates = _deduplicate_candidates(all_candidates)
        unique_candidates.sort(key=lambda c: c.similarity, reverse=True)
        
        return unique_candidates[:top_k]
        
    except Exception as e:
        print(f"âš ï¸ è·¯å¾„Bæ‰§è¡Œå¤±è´¥: {e}")
        return []


def _extract_phrases_with_llm(
    user_input: str,
    max_candidates: int
) -> List[str]:
    """
    ä½¿ç”¨LLMä»ç”¨æˆ·è¾“å…¥ä¸­æå–å¯èƒ½çš„åƒåœ¾å“åçŸ­è¯­
    
    Returns:
        å€™é€‰çŸ­è¯­åˆ—è¡¨ï¼ˆæœ€å¤šmax_candidatesä¸ªï¼‰
    """
    prompt = f"""ã‚ãªãŸã¯åŒ—ä¹å·å¸‚ã®ã”ã¿åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰ã€æ¨ã¦ãŸã„ç‰©å“ã®åç§°ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. ç‰©å“åã®ã¿ã‚’æŠ½å‡ºï¼ˆèª¬æ˜æ–‡ã‚„å‹•è©ã¯å«ã‚ãªã„ï¼‰
2. æœ€å¤§{max_candidates}å€‹ã¾ã§
3. JSONå½¢å¼ã§å‡ºåŠ›: {{"candidates": ["ç‰©å“1", "ç‰©å“2"]}}
4. å€™è£œãŒãªã„å ´åˆ: {{"candidates": []}}

ã€å…¥åŠ›ã€‘
{user_input}

ã€å‡ºåŠ›ã€‘ï¼ˆJSONå½¢å¼ã®ã¿ã€èª¬æ˜ä¸è¦ï¼‰
"""

    try:
        response = ollama.chat(
            model=HybridConfig.LLM_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ç‰©å“åæŠ½å‡ºã®å°‚é–€ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            options={
                "temperature": HybridConfig.LLM_TEMPERATURE
            }
        )
        
        content = response["message"]["content"]
        
        # JSONè§£æï¼ˆè¤‡æ•°ã®å½¢å¼ã«å¯¾å¿œï¼‰
        # Case 1: ç›´æ¥JSON
        if content.strip().startswith("{"):
            data = json.loads(content)
            return data.get("candidates", [])[:max_candidates]
        
        # Case 2: Markdown code blockå†…ã®JSON
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0].strip()
            data = json.loads(json_str)
            return data.get("candidates", [])[:max_candidates]
        
        # Case 3: è§£æå¤±æ•—
        print(f"âš ï¸ LLMå‡ºåŠ›ã®è§£æå¤±æ•—: {content[:100]}")
        return []
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return []
    except Exception as e:
        print(f"âš ï¸ LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def _deduplicate_candidates(candidates: List[Candidate]) -> List[Candidate]:
    """
    å€™è£œã®é‡è¤‡é™¤å»ï¼ˆåŒã˜å“åã®å ´åˆã€æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ä¿æŒï¼‰
    """
    seen = {}
    for c in candidates:
        if c.item_name not in seen or c.similarity > seen[c.item_name].similarity:
            seen[c.item_name] = c
    
    return list(seen.values())


# ========== å€™è£œåˆä½µã¨æ±ºç­– ==========

def merge_candidates(
    candidates_a: List[Candidate],
    candidates_b: List[Candidate]
) -> List[Candidate]:
    """
    è·¯å¾„Aå’Œè·¯å¾„Bçš„å€™é€‰è¿›è¡Œåˆå¹¶ã€å»é‡ã€é‡æ’åº
    
    ç­–ç•¥ï¼š
    1. åˆå¹¶ä¸¤ä¸ªåˆ—è¡¨
    2. ç›¸åŒå“åçš„å€™é€‰ï¼Œæƒé‡æå‡ï¼ˆå–å¹³å‡åˆ†+0.1ï¼‰
    3. æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
    """
    all_candidates = {}
    
    # å¤„ç†è·¯å¾„Aå€™é€‰
    for c in candidates_a:
        all_candidates[c.item_name] = {
            "candidate": c,
            "sources": ["path_a"],
            "scores": [c.similarity]
        }
    
    # å¤„ç†è·¯å¾„Bå€™é€‰ï¼ˆå¦‚æœå“åå·²å­˜åœ¨ï¼Œæ ‡è®°ä¸ºåŒè·¯å¾„å‘½ä¸­ï¼‰
    for c in candidates_b:
        if c.item_name in all_candidates:
            # åŒè·¯å¾„å‘½ä¸­ - æå‡ç½®ä¿¡åº¦
            all_candidates[c.item_name]["sources"].append("path_b")
            all_candidates[c.item_name]["scores"].append(c.similarity)
        else:
            all_candidates[c.item_name] = {
                "candidate": c,
                "sources": ["path_b"],
                "scores": [c.similarity]
            }
    
    # è®¡ç®—æœ€ç»ˆåˆ†æ•°
    merged = []
    for item_name, data in all_candidates.items():
        candidate = data["candidate"]
        
        # åŒè·¯å¾„å‘½ä¸­ï¼šå–å¹³å‡åˆ†+0.1 bonus
        if len(data["sources"]) > 1:
            final_score = sum(data["scores"]) / len(data["scores"]) + 0.1
            candidate.source = "both"
        else:
            final_score = data["scores"][0]
        
        # æ›´æ–°åˆ†æ•°
        candidate.similarity = min(final_score, 1.0)  # ç¡®ä¿ä¸è¶…è¿‡1.0
        merged.append(candidate)
    
    # æŒ‰åˆ†æ•°æ’åº
    merged.sort(key=lambda c: c.similarity, reverse=True)
    
    return merged


# ========== ä¸»å‡½æ•°ï¼šHybridå“åæŒ‡ç§° ==========

def hybrid_grounding(
    user_input: str,
    gomi_collection: chromadb.Collection,
    force_full_path: bool = False
) -> GroundingResult:
    """
    Hybridå“åæŒ‡ç§°ä¸»å‡½æ•°
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        gomi_collection: ChromaDBåƒåœ¾åˆ†ç±»collection
        force_full_path: å¼ºåˆ¶æ‰§è¡Œå®Œæ•´åŒè·¯å¾„ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
    Returns:
        GroundingResultå¯¹è±¡
    """
    start_time = time.perf_counter()
    
    # å†³å®šæ˜¯å¦ä½¿ç”¨å¿«é€Ÿè·¯å¾„
    use_fast_path = (
        not force_full_path and 
        len(user_input) < HybridConfig.SHORT_INPUT_THRESHOLD
    )
    
    if use_fast_path:
        # å¿«é€Ÿè·¯å¾„ï¼šä»…è·¯å¾„A
        print(f"ğŸš€ å¿«é€Ÿè·¯å¾„ï¼ˆè¾“å…¥é•¿åº¦: {len(user_input)}å­—ç¬¦ï¼‰")
        candidates_a = path_a_global_embedding(user_input, gomi_collection)
        final_candidates = candidates_a
        path_used = "path_a_only"
    else:
        # å®Œæ•´è·¯å¾„ï¼šåŒè·¯å¾„å¹¶è¡Œï¼ˆç®€åŒ–ç‰ˆä¸²è¡Œï¼‰
        print(f"ğŸ” å®Œæ•´è·¯å¾„ï¼ˆè¾“å…¥é•¿åº¦: {len(user_input)}å­—ç¬¦ï¼‰")
        
        # è·¯å¾„A
        candidates_a = path_a_global_embedding(user_input, gomi_collection)
        
        # è·¯å¾„Bï¼ˆå¸¦é™çº§ï¼‰
        try:
            candidates_b = path_b_llm_filter(user_input, gomi_collection)
        except Exception as e:
            print(f"âš ï¸ è·¯å¾„Bå¤±è´¥ï¼Œé™çº§åˆ°è·¯å¾„A: {e}")
            candidates_b = []
        
        # åˆå¹¶å€™é€‰
        if candidates_b:
            final_candidates = merge_candidates(candidates_a, candidates_b)
            path_used = "both"
        else:
            final_candidates = candidates_a
            path_used = "degraded"
    
    # ç½®ä¿¡åº¦è¯„ä¼°
    confidence_level, is_ambiguous = _evaluate_confidence(final_candidates)
    
    # æ„å»ºç»“æœ
    end_time = time.perf_counter()
    
    result = GroundingResult(
        candidates=final_candidates,
        primary_candidate=final_candidates[0] if final_candidates else None,
        is_ambiguous=is_ambiguous,
        confidence_level=confidence_level,
        execution_time_ms=(end_time - start_time) * 1000,
        path_used=path_used
    )
    
    return result


def _evaluate_confidence(candidates: List[Candidate]) -> Tuple[str, bool]:
    """
    è¯„ä¼°ç½®ä¿¡åº¦çº§åˆ«
    
    Returns:
        (confidence_level, is_ambiguous)
    """
    if not candidates:
        return "low", False
    
    top_score = candidates[0].similarity
    is_ambiguous = False
    
    # æ£€æŸ¥æ­§ä¹‰ï¼ˆTop1å’ŒTop2å·®å€¼å°ï¼‰
    if len(candidates) >= 2:
        score_diff = top_score - candidates[1].similarity
        is_ambiguous = score_diff < HybridConfig.AMBIGUITY_THRESHOLD
    
    # ç½®ä¿¡åº¦åˆ†çº§
    if top_score >= HybridConfig.CONFIDENCE_THRESHOLD_HIGH:
        confidence_level = "high"
    elif top_score >= HybridConfig.CONFIDENCE_THRESHOLD_LOW:
        confidence_level = "medium"
    else:
        confidence_level = "low"
    
    return confidence_level, is_ambiguous


# ========== å·¥å…·å‡½æ•° ==========

def format_grounding_result(result: GroundingResult) -> str:
    """
    æ ¼å¼åŒ–æŒ‡ç§°ç»“æœç”¨äºæ—¥å¿—è¾“å‡º
    """
    lines = [
        f"\n{'='*60}",
        f"Hybrid Grounding ç»“æœ",
        f"{'='*60}",
        f"æ‰§è¡Œè€—æ—¶: {result.execution_time_ms:.2f}ms",
        f"è·¯å¾„ä½¿ç”¨: {result.path_used}",
        f"ç½®ä¿¡åº¦: {result.confidence_level}",
        f"æ˜¯å¦æ­§ä¹‰: {result.is_ambiguous}",
        f"\nå€™é€‰åˆ—è¡¨ (å…±{len(result.candidates)}ä¸ª):"
    ]
    
    for i, c in enumerate(result.candidates, 1):
        lines.append(
            f"  {i}. {c.item_name} (score: {c.similarity:.3f}, source: {c.source})"
        )
    
    if result.primary_candidate:
        lines.append(f"\nä¸»å€™é€‰: {result.primary_candidate.item_name}")
    
    lines.append(f"{'='*60}\n")
    
    return "\n".join(lines)
```

---

### 3.2 é›†æˆåˆ°ç°æœ‰RAGæµç¨‹

**ä¿®æ”¹æ–‡ä»¶**: `rag/rag_demo3.py`

åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥ï¼š

```python
# åœ¨ç°æœ‰importä¹‹åæ·»åŠ 
from hybrid_grounding import (
    hybrid_grounding,
    format_grounding_result,
    HybridConfig
)
```

ä¿®æ”¹ `rag_retrieve_extended` å‡½æ•°ï¼š

```python
def rag_retrieve_extended(
    user_input,
    gomi_collection,
    area_collection,
    known_items,  # ä¿ç•™ä½†ä¸å†ä½¿ç”¨
    area_meta,
    knowledge_collection=None,
    known_areas=AREAS,
    top_k=3,
    use_hybrid=True  # æ–°å¢å¼€å…³
):
    context_parts = []
    references = []

    # ========= æ–°ï¼šä½¿ç”¨Hybridå“åè¯†åˆ« =========
    if use_hybrid:
        grounding_result = hybrid_grounding(user_input, gomi_collection)
        
        # è°ƒè¯•è¾“å‡º
        print(format_grounding_result(grounding_result))
        
        # æ ¹æ®ç½®ä¿¡åº¦å†³å®šæ˜¯å¦ä½¿ç”¨å€™é€‰
        if grounding_result.confidence_level in ["high", "medium"]:
            primary = grounding_result.primary_candidate
            
            # å¦‚æœå­˜åœ¨æ­§ä¹‰ï¼Œåœ¨contextä¸­æ·»åŠ å…¶ä»–å€™é€‰
            if grounding_result.is_ambiguous and len(grounding_result.candidates) > 1:
                items_text = " / ".join([
                    c.item_name for c in grounding_result.candidates[:3]
                ])
                context_parts.append(
                    f"ã€æ³¨æ„ã€‘ä»¥ä¸‹ã®å“åå€™è£œãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {items_text}\n"
                    f"æœ€ã‚‚é–¢é€£æ€§ãŒé«˜ã„ã®ã¯ã€Œ{primary.item_name}ã€ã§ã™ã€‚\n"
                )
            
            # æ„å»ºåƒåœ¾åˆ†ç±»ä¿¡æ¯
            gomi_context = (
                f"å“å: {primary.metadata.get('å“å','')}\n"
                f"å‡ºã—æ–¹: {primary.metadata.get('å‡ºã—æ–¹','')}\n"
                f"å‚™è€ƒ: {primary.metadata.get('å‚™è€ƒ','')}"
            )
            context_parts.append(f"ã€ã”ã¿åˆ†åˆ¥æƒ…å ±ã€‘\n{gomi_context}")
            
        else:
            # ä½ç½®ä¿¡åº¦ - é™çº§åˆ°çŸ¥è¯†åº“æœç´¢
            context_parts.append(
                "ã€æ³¨æ„ã€‘ç‰¹å®šã®ã”ã¿å“åãŒè­˜åˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                "ä¸€èˆ¬çš„ãªæƒ…å ±ã§å›ç­”ã—ã¾ã™ã€‚\n"
            )
    else:
        # åŸæœ‰MeCabé€»è¾‘ï¼ˆé™çº§è·¯å¾„ï¼‰
        keys = extract_keywords(user_input, known_items, known_areas)
        if keys["å“å"]:
            gomi_hits = query_chroma(gomi_collection, keys["å“å"], n=top_k)
            # ... åŸæœ‰é€»è¾‘
    
    # ========= ç”ºåæ£€ç´¢ï¼ˆä¿æŒä¸å˜ï¼‰ =========
    keys = extract_keywords(user_input, known_items=[], known_areas=known_areas)
    if keys["ç”ºå"] and area_meta:
        matched = [h for h in area_meta if h.get("ç”ºå") == keys["ç”ºå"]]
        if matched:
            formatted = []
            for h in matched:
                formatted.append(
                    f"{h.get('ç”ºå','ä¸æ˜')} ã®åé›†æƒ…å ±:\n"
                    f"- å®¶åº­ã”ã¿: {h.get('å®¶åº­ã”ã¿ã®åé›†æ—¥','ä¸æ˜')}\n"
                    f"- ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯: {h.get('ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯ã®åé›†æ—¥','ä¸æ˜')}\n"
                    f"- ç²—å¤§ã”ã¿: {h.get('ç²—å¤§ã”ã¿ã®åé›†æ—¥ï¼ˆäº‹å‰ç”³è¾¼åˆ¶ï¼‰','ä¸æ˜')}"
                )
            context_parts.append("ã€ç”ºåæƒ…å ±ã€‘\n" + "\n\n".join(formatted))
    
    # ========= çŸ¥è¯†åº“æ£€ç´¢ï¼ˆä¿æŒä¸å˜ï¼‰ =========
    if knowledge_collection:
        knowledge_hits = query_chroma(knowledge_collection, user_input, n=top_k)
        if knowledge_hits:
            for h in knowledge_hits[:2]:
                references.append({
                    "file": h.get("file", "?"),
                    "page": h.get("page", "?"),
                    "chunk": h.get("chunk", "?"),
                    "text": h.get("text", "")[:300]
                })
            knowledge_context = "\n\n".join([
                f"ãƒ•ã‚¡ã‚¤ãƒ«: {h.get('file','')}, p.{h.get('page','?')}, chunk {h.get('chunk','?')}"
                for h in knowledge_hits[:2]
            ])
            context_parts.append(f"ã€ãƒ¦ãƒ¼ã‚¶ãƒŠãƒ¬ãƒƒã‚¸æƒ…å ±ã€‘\n{knowledge_context}")
    
    # ========= æ„å»ºæœ€ç»ˆpromptï¼ˆä¿æŒä¸å˜ï¼‰ =========
    context = "\n\n".join(context_parts) if context_parts else "è©²å½“æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    prompt = f"""
ã‚ãªãŸã¯åŒ—ä¹å·å¸‚ã®ã”ã¿åˆ†åˆ¥æ¡ˆå†…ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
ä»¥ä¸‹ã«ç¤ºã™ã€ã”ã¿åˆ†åˆ¥æƒ…å ±ã€‘ã®ã¿ã‚’å”¯ä¸€ã®äº‹å®Ÿæƒ…å ±ã¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

ã€ã”ã¿åˆ†åˆ¥æƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{user_input}

ã€å‡ºåŠ›å½¢å¼ã€‘
- å“å
- å“åã®å‡ºã—æ–¹
- å‚™è€ƒ
- è©²å½“ç”ºåã®åé›†æ—¥ï¼ˆä¸æ˜ãªå ´åˆã¯ã€Œä¸æ˜ã€ã¨è¨˜è¼‰ï¼‰
"""
    return prompt, references
```

---

### 3.3 å‘åå…¼å®¹æ€§å¼€å…³

åœ¨ `backend/app.py` ä¸­æ·»åŠ é…ç½®å¼€å…³ï¼š

```python
# åœ¨å…¨å±€å˜é‡åŒºåŸŸæ·»åŠ 
ENABLE_HYBRID_GROUNDING = os.getenv("ENABLE_HYBRID_GROUNDING", "true").lower() == "true"

# åœ¨APIç«¯ç‚¹ä¸­ä¼ é€’å‚æ•°
@app.post("/api/bot/respond")
async def rag_respond(req: PromptRequest):
    rag_prompt, references = rag_retrieve_extended(
        req.prompt,
        gomi_collection,
        knowledge_collection=knowledge_collection,
        area_collection=area_collection,
        known_items=known_items,
        area_meta=area_meta,
        top_k=2,
        use_hybrid=ENABLE_HYBRID_GROUNDING  # æ·»åŠ å¼€å…³
    )
    # ... å…¶ä½™ä»£ç ä¸å˜
```

---

## 4. é›†æˆä¸æµ‹è¯•

### 4.1 å•å…ƒæµ‹è¯•

**æ–‡ä»¶è·¯å¾„**: `rag/test_hybrid.py`

```python
#!/usr/bin/env python3
"""
Hybridå“åæŒ‡ç§°ç³»ç»Ÿå•å…ƒæµ‹è¯•
"""

import pytest
import chromadb
from hybrid_grounding import (
    hybrid_grounding,
    path_a_global_embedding,
    path_b_llm_filter,
    merge_candidates,
    HybridConfig
)
from rag_demo3 import load_jsonl, build_chroma


# ========== Fixtures ==========

@pytest.fixture(scope="module")
def gomi_collection():
    """æµ‹è¯•ç”¨åƒåœ¾åˆ†ç±»collection"""
    gomi_docs, gomi_meta = load_jsonl("rag_docs_merged.jsonl", key="å“å")
    collection = build_chroma(gomi_docs, gomi_meta, name="gomi_test")
    yield collection
    # Cleanup
    client = chromadb.PersistentClient(path="./chroma_db")
    try:
        client.delete_collection("gomi_test")
    except:
        pass


# ========== è·¯å¾„Aæµ‹è¯• ==========

def test_path_a_short_input(gomi_collection):
    """æµ‹è¯•è·¯å¾„A - çŸ­è¾“å…¥"""
    user_input = "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"
    candidates = path_a_global_embedding(user_input, gomi_collection, top_k=3)
    
    assert len(candidates) > 0, "åº”è¿”å›è‡³å°‘1ä¸ªå€™é€‰"
    assert candidates[0].item_name is not None, "åº”è¿”å›æœ‰æ•ˆå“å"
    assert 0 <= candidates[0].similarity <= 1, "ç›¸ä¼¼åº¦åº”åœ¨0-1ä¹‹é—´"
    
    # éªŒè¯è¿”å›çš„å“åç›¸å…³æ€§
    top_name = candidates[0].item_name
    assert "ãƒ‘ã‚½ã‚³ãƒ³" in top_name or "ãƒãƒ¼ãƒˆ" in top_name, f"å“ååº”åŒ…å«ç›¸å…³è¯æ±‡ï¼Œå®é™…: {top_name}"


def test_path_a_long_input(gomi_collection):
    """æµ‹è¯•è·¯å¾„A - é•¿è¾“å…¥"""
    user_input = "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’å‡¦åˆ†ã—ãŸã„ã§ã™"
    candidates = path_a_global_embedding(user_input, gomi_collection, top_k=3)
    
    assert len(candidates) > 0, "é•¿è¾“å…¥ä¹Ÿåº”è¿”å›å€™é€‰"
    print(f"\né•¿è¾“å…¥Top-3å€™é€‰: {[c.item_name for c in candidates]}")


# ========== è·¯å¾„Bæµ‹è¯• ==========

def test_path_b_extraction(gomi_collection):
    """æµ‹è¯•è·¯å¾„B - LLMå€™é€‰æå–"""
    user_input = "å¤ã„ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã‚’æ¨ã¦ãŸã„"
    candidates = path_b_llm_filter(user_input, gomi_collection)
    
    assert len(candidates) > 0, "åº”æå–è‡³å°‘1ä¸ªå€™é€‰"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸå“å
    item_names = [c.item_name for c in candidates]
    print(f"\nè·¯å¾„Bæå–çš„å“å: {item_names}")
    
    has_pc = any("ãƒ‘ã‚½ã‚³ãƒ³" in name for name in item_names)
    has_printer = any("ãƒ—ãƒªãƒ³ã‚¿ãƒ¼" in name or "ãƒ—ãƒªãƒ³ã‚¿" in name for name in item_names)
    
    assert has_pc or has_printer, f"åº”åŒ…å«ãƒ‘ã‚½ã‚³ãƒ³ã¾ãŸã¯ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ï¼Œå®é™…: {item_names}"


def test_path_b_timeout_handling(gomi_collection):
    """æµ‹è¯•è·¯å¾„B - è¶…æ—¶å¤„ç†"""
    # æ¨¡æ‹Ÿè¶…é•¿è¾“å…¥
    user_input = "x" * 1000
    
    try:
        candidates = path_b_llm_filter(user_input, gomi_collection)
        # åº”èƒ½æ­£å¸¸è¿”å›ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
        assert isinstance(candidates, list)
    except Exception as e:
        pytest.fail(f"è·¯å¾„Båº”æ•è·å¼‚å¸¸è€ŒéæŠ›å‡º: {e}")


# ========== åˆå¹¶é€»è¾‘æµ‹è¯• ==========

def test_merge_candidates(gomi_collection):
    """æµ‹è¯•å€™é€‰åˆå¹¶é€»è¾‘"""
    from hybrid_grounding import Candidate
    
    # æ¨¡æ‹Ÿè·¯å¾„Aå€™é€‰
    candidates_a = [
        Candidate("ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³", 0.7, "path_a", {}),
        Candidate("ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒ‘ã‚½ã‚³ãƒ³", 0.5, "path_a", {})
    ]
    
    # æ¨¡æ‹Ÿè·¯å¾„Bå€™é€‰ï¼ˆæœ‰é‡å ï¼‰
    candidates_b = [
        Candidate("ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³", 0.65, "path_b", {}),  # é‡å 
        Candidate("ãƒ—ãƒªãƒ³ã‚¿ãƒ¼", 0.6, "path_b", {})
    ]
    
    merged = merge_candidates(candidates_a, candidates_b)
    
    # éªŒè¯å»é‡
    item_names = [c.item_name for c in merged]
    assert len(item_names) == len(set(item_names)), "åº”æ— é‡å¤å“å"
    
    # éªŒè¯åŒè·¯å¾„å‘½ä¸­çš„boost
    notebook = next((c for c in merged if c.item_name == "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"), None)
    assert notebook is not None
    assert notebook.source == "both", "åº”æ ‡è®°ä¸ºåŒè·¯å¾„å‘½ä¸­"
    assert notebook.similarity > 0.7, f"åŒè·¯å¾„å‘½ä¸­åº”æå‡åˆ†æ•°ï¼Œå®é™…: {notebook.similarity}"


# ========== å®Œæ•´æµç¨‹æµ‹è¯• ==========

def test_hybrid_full_pipeline_short(gomi_collection):
    """æµ‹è¯•å®Œæ•´æµç¨‹ - çŸ­è¾“å…¥ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰"""
    user_input = "å†·è”µåº«"
    result = hybrid_grounding(user_input, gomi_collection)
    
    assert result.primary_candidate is not None, "åº”è¿”å›ä¸»å€™é€‰"
    assert result.path_used == "path_a_only", "çŸ­è¾“å…¥åº”ä½¿ç”¨å¿«é€Ÿè·¯å¾„"
    assert result.execution_time_ms < 200, f"å¿«é€Ÿè·¯å¾„åº”<200msï¼Œå®é™…: {result.execution_time_ms}ms"
    assert "å†·è”µ" in result.primary_candidate.item_name


def test_hybrid_full_pipeline_long(gomi_collection):
    """æµ‹è¯•å®Œæ•´æµç¨‹ - é•¿è¾“å…¥ï¼ˆåŒè·¯å¾„ï¼‰"""
    user_input = "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨å¤ã„ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã€ãã‚Œã‹ã‚‰å£Šã‚ŒãŸé›»å­ãƒ¬ãƒ³ã‚¸ã‚’å‡¦åˆ†ã—ãŸã„ã§ã™"
    result = hybrid_grounding(user_input, gomi_collection, force_full_path=True)
    
    assert result.primary_candidate is not None, "åº”è¿”å›ä¸»å€™é€‰"
    assert result.path_used in ["both", "degraded"], "é•¿è¾“å…¥åº”å°è¯•åŒè·¯å¾„"
    assert len(result.candidates) > 0, "åº”è¿”å›å€™é€‰åˆ—è¡¨"
    
    print(f"\né•¿è¾“å…¥ç»“æœ:")
    print(f"  è·¯å¾„: {result.path_used}")
    print(f"  è€—æ—¶: {result.execution_time_ms:.2f}ms")
    print(f"  ç½®ä¿¡åº¦: {result.confidence_level}")
    print(f"  ä¸»å€™é€‰: {result.primary_candidate.item_name}")


def test_hybrid_ambiguity_detection(gomi_collection):
    """æµ‹è¯•æ­§ä¹‰æ£€æµ‹"""
    # æ„é€ ä¸€ä¸ªå¯èƒ½äº§ç”Ÿæ­§ä¹‰çš„è¾“å…¥
    user_input = "å®¶é›»è£½å“"  # æ¨¡ç³Šè¾“å…¥
    result = hybrid_grounding(user_input, gomi_collection)
    
    assert len(result.candidates) > 0
    print(f"\næ­§ä¹‰æ£€æµ‹:")
    print(f"  æ˜¯å¦æ­§ä¹‰: {result.is_ambiguous}")
    print(f"  å€™é€‰: {[c.item_name for c in result.candidates[:3]]}")


def test_hybrid_low_confidence(gomi_collection):
    """æµ‹è¯•ä½ç½®ä¿¡åº¦åœºæ™¯"""
    user_input = "ã‚ˆãã‚ã‹ã‚‰ãªã„ã‚‚ã®"  # æ— æ•ˆè¾“å…¥
    result = hybrid_grounding(user_input, gomi_collection)
    
    if result.primary_candidate:
        assert result.confidence_level == "low", "æ— æ•ˆè¾“å…¥åº”è¿”å›ä½ç½®ä¿¡åº¦"
        print(f"\nä½ç½®ä¿¡åº¦åœºæ™¯: {result.primary_candidate.item_name} (score: {result.primary_candidate.similarity:.3f})")


# ========== æ€§èƒ½æµ‹è¯• ==========

def test_performance_benchmark(gomi_collection):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    test_cases = [
        ("ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³", "short"),
        ("å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’å‡¦åˆ†ã—ãŸã„", "long")
    ]
    
    results = []
    for user_input, case_type in test_cases:
        result = hybrid_grounding(user_input, gomi_collection)
        results.append({
            "type": case_type,
            "time_ms": result.execution_time_ms,
            "path": result.path_used
        })
    
    print("\n=== æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    for r in results:
        print(f"{r['type']:6s} | {r['time_ms']:6.2f}ms | {r['path']}")
    
    # éªŒè¯æ€§èƒ½è¦æ±‚
    short_time = next(r["time_ms"] for r in results if r["type"] == "short")
    assert short_time < 200, f"çŸ­è¾“å…¥åº”<200msï¼Œå®é™…: {short_time}ms"


# ========== è¿è¡Œæµ‹è¯• ==========

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
cd rag
python -m pytest test_hybrid.py -v -s
```

---

### 4.2 é›†æˆæµ‹è¯•è„šæœ¬

**æ–‡ä»¶è·¯å¾„**: `rag/benchmark_hybrid.py`

```python
#!/usr/bin/env python3
"""
Hybridå“åæŒ‡ç§°ç³»ç»Ÿ - ç«¯åˆ°ç«¯åŸºå‡†æµ‹è¯•
"""

import json
import time
from pathlib import Path
from hybrid_grounding import hybrid_grounding
from rag_demo3 import load_jsonl, build_chroma
import chromadb


def load_test_cases():
    """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
    test_file = Path("test_inputs.json")
    
    if not test_file.exists():
        # åˆ›å»ºé»˜è®¤æµ‹è¯•ç”¨ä¾‹
        test_data = {
            "test_cases": [
                {
                    "input": "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’æ¨ã¦ãŸã„",
                    "expected_keywords": ["ãƒ‘ã‚½ã‚³ãƒ³", "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"],
                    "type": "short"
                },
                {
                    "input": "å†·è”µåº«",
                    "expected_keywords": ["å†·è”µåº«"],
                    "type": "short"
                },
                {
                    "input": "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨å¤ã„ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã€ãã‚Œã‹ã‚‰å£Šã‚ŒãŸé›»å­ãƒ¬ãƒ³ã‚¸ã‚’å‡¦åˆ†ã—ãŸã„ã§ã™",
                    "expected_keywords": ["ãƒ‘ã‚½ã‚³ãƒ³", "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼", "é›»å­ãƒ¬ãƒ³ã‚¸"],
                    "type": "long"
                },
                {
                    "input": "å­ä¾›ãŒå¤§ãããªã£ãŸã®ã§ã€ãƒ™ãƒ“ãƒ¼ã‚«ãƒ¼ã‚„ãƒ™ãƒ“ãƒ¼ãƒ™ãƒƒãƒ‰ã€ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ¨ã¦ãŸã„",
                    "expected_keywords": ["ãƒ™ãƒ“ãƒ¼ã‚«ãƒ¼", "ãƒ™ãƒ“ãƒ¼ãƒ™ãƒƒãƒ‰", "ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆ"],
                    "type": "long"
                },
                {
                    "input": "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯è£½ã®åç´ç®±",
                    "expected_keywords": ["ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯", "åç´", "ç®±"],
                    "type": "medium"
                }
            ]
        }
        test_file.write_text(json.dumps(test_data, ensure_ascii=False, indent=2), encoding="utf-8")
    
    return json.loads(test_file.read_text(encoding="utf-8"))


def evaluate_result(result, expected_keywords):
    """è¯„ä¼°ç»“æœå‡†ç¡®æ€§"""
    if not result.primary_candidate:
        return False, "æ— ä¸»å€™é€‰"
    
    item_name = result.primary_candidate.item_name
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€é¢„æœŸå…³é”®è¯
    for keyword in expected_keywords:
        if keyword in item_name:
            return True, f"åŒ¹é…: {keyword}"
    
    return False, f"æœªåŒ¹é…: {item_name}"


def run_benchmark():
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("=" * 80)
    print("Hybridå“åæŒ‡ç§°ç³»ç»Ÿ - åŸºå‡†æµ‹è¯•")
    print("=" * 80)
    
    # åˆå§‹åŒ–collection
    print("\nåˆå§‹åŒ–ChromaDB...")
    gomi_docs, gomi_meta = load_jsonl("rag_docs_merged.jsonl", key="å“å")
    gomi_collection = build_chroma(gomi_docs, gomi_meta, name="gomi")
    
    # åŠ è½½æµ‹è¯•ç”¨ä¾‹
    test_data = load_test_cases()
    test_cases = test_data["test_cases"]
    
    print(f"\næµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}")
    print("-" * 80)
    
    # æ‰§è¡Œæµ‹è¯•
    results = []
    
    for i, case in enumerate(test_cases, 1):
        user_input = case["input"]
        expected = case["expected_keywords"]
        case_type = case.get("type", "unknown")
        
        print(f"\n[{i}/{len(test_cases)}] {case_type.upper()}")
        print(f"è¾“å…¥: {user_input[:60]}...")
        
        # æ‰§è¡ŒHybridæŒ‡ç§°
        result = hybrid_grounding(user_input, gomi_collection)
        
        # è¯„ä¼°ç»“æœ
        is_correct, reason = evaluate_result(result, expected)
        
        # è®°å½•ç»“æœ
        results.append({
            "input": user_input,
            "type": case_type,
            "primary_candidate": result.primary_candidate.item_name if result.primary_candidate else None,
            "similarity": result.primary_candidate.similarity if result.primary_candidate else 0,
            "confidence": result.confidence_level,
            "is_ambiguous": result.is_ambiguous,
            "execution_time_ms": result.execution_time_ms,
            "path_used": result.path_used,
            "is_correct": is_correct,
            "reason": reason
        })
        
        # æ‰“å°ç»“æœ
        status = "âœ…" if is_correct else "âŒ"
        print(f"{status} ä¸»å€™é€‰: {result.primary_candidate.item_name if result.primary_candidate else 'None'}")
        print(f"   ç›¸ä¼¼åº¦: {result.primary_candidate.similarity:.3f if result.primary_candidate else 0}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence_level}")
        print(f"   è·¯å¾„: {result.path_used}")
        print(f"   è€—æ—¶: {result.execution_time_ms:.2f}ms")
        print(f"   è¯„ä¼°: {reason}")
    
    # ç»Ÿè®¡æ€»ç»“
    print("\n" + "=" * 80)
    print("ç»Ÿè®¡æ€»ç»“")
    print("=" * 80)
    
    total = len(results)
    correct = sum(1 for r in results if r["is_correct"])
    accuracy = correct / total * 100 if total > 0 else 0
    
    avg_time = sum(r["execution_time_ms"] for r in results) / total
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_stats = {}
    for r in results:
        t = r["type"]
        if t not in type_stats:
            type_stats[t] = {"total": 0, "correct": 0, "time": []}
        type_stats[t]["total"] += 1
        if r["is_correct"]:
            type_stats[t]["correct"] += 1
        type_stats[t]["time"].append(r["execution_time_ms"])
    
    print(f"\næ€»ä½“å‡†ç¡®ç‡: {accuracy:.1f}% ({correct}/{total})")
    print(f"å¹³å‡è€—æ—¶: {avg_time:.2f}ms")
    
    print("\næŒ‰ç±»å‹ç»Ÿè®¡:")
    for t, stats in type_stats.items():
        t_accuracy = stats["correct"] / stats["total"] * 100
        t_avg_time = sum(stats["time"]) / len(stats["time"])
        print(f"  {t:8s}: {t_accuracy:5.1f}% ({stats['correct']}/{stats['total']}) | "
              f"å¹³å‡è€—æ—¶: {t_avg_time:6.2f}ms")
    
    # è·¯å¾„ä½¿ç”¨ç»Ÿè®¡
    path_counts = {}
    for r in results:
        path = r["path_used"]
        path_counts[path] = path_counts.get(path, 0) + 1
    
    print("\nè·¯å¾„ä½¿ç”¨ç»Ÿè®¡:")
    for path, count in path_counts.items():
        print(f"  {path:15s}: {count:2d} ({count/total*100:.1f}%)")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    confidence_counts = {}
    for r in results:
        conf = r["confidence"]
        confidence_counts[conf] = confidence_counts.get(conf, 0) + 1
    
    print("\nç½®ä¿¡åº¦åˆ†å¸ƒ:")
    for conf in ["high", "medium", "low"]:
        count = confidence_counts.get(conf, 0)
        print(f"  {conf:8s}: {count:2d} ({count/total*100:.1f}%)")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = Path("benchmark_results.json")
    output_file.write_text(
        json.dumps({
            "summary": {
                "total": total,
                "correct": correct,
                "accuracy": accuracy,
                "avg_time_ms": avg_time
            },
            "results": results
        }, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 80)
    
    return accuracy >= 85  # ç›®æ ‡å‡†ç¡®ç‡85%


if __name__ == "__main__":
    success = run_benchmark()
    exit(0 if success else 1)
```

è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼š

```bash
cd rag
python benchmark_hybrid.py
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–

ä¿®æ”¹ `hybrid_grounding.py` ä¸­çš„ `hybrid_grounding` å‡½æ•°ï¼Œå®ç°è·¯å¾„Aå’Œè·¯å¾„Bçš„å¹¶è¡Œæ‰§è¡Œï¼š

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def hybrid_grounding(
    user_input: str,
    gomi_collection: chromadb.Collection,
    force_full_path: bool = False,
    enable_parallel: bool = True  # æ–°å¢å¼€å…³
) -> GroundingResult:
    """
    Hybridå“åæŒ‡ç§°ä¸»å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ”¯æŒå¹¶è¡Œæ‰§è¡Œï¼‰
    """
    start_time = time.perf_counter()
    
    use_fast_path = (
        not force_full_path and 
        len(user_input) < HybridConfig.SHORT_INPUT_THRESHOLD
    )
    
    if use_fast_path:
        # å¿«é€Ÿè·¯å¾„ï¼ˆä¸å˜ï¼‰
        candidates_a = path_a_global_embedding(user_input, gomi_collection)
        final_candidates = candidates_a
        path_used = "path_a_only"
    else:
        # å®Œæ•´è·¯å¾„ï¼šå¹¶è¡Œæ‰§è¡Œ
        if enable_parallel:
            candidates_a = []
            candidates_b = []
            
            with ThreadPoolExecutor(max_workers=2) as executor:
                future_a = executor.submit(
                    path_a_global_embedding, user_input, gomi_collection
                )
                future_b = executor.submit(
                    path_b_llm_filter, user_input, gomi_collection
                )
                
                # æ”¶é›†ç»“æœ
                for future in as_completed([future_a, future_b]):
                    try:
                        if future == future_a:
                            candidates_a = future.result()
                        else:
                            candidates_b = future.result()
                    except Exception as e:
                        print(f"âš ï¸ å¹¶è¡Œæ‰§è¡Œé”™è¯¯: {e}")
                        if future == future_b:
                            candidates_b = []
        else:
            # ä¸²è¡Œæ‰§è¡Œï¼ˆåŸé€»è¾‘ï¼‰
            candidates_a = path_a_global_embedding(user_input, gomi_collection)
            try:
                candidates_b = path_b_llm_filter(user_input, gomi_collection)
            except:
                candidates_b = []
        
        # åˆå¹¶å€™é€‰
        if candidates_b:
            final_candidates = merge_candidates(candidates_a, candidates_b)
            path_used = "both"
        else:
            final_candidates = candidates_a
            path_used = "degraded"
    
    # ... å…¶ä½™ä»£ç ä¸å˜
```

**é¢„æœŸæ€§èƒ½æå‡**ï¼šå¹¶è¡Œæ‰§è¡Œå¯å°†å®Œæ•´è·¯å¾„çš„å»¶è¿Ÿä»~450msé™ä½è‡³~300msï¼ˆçº¦33%æå‡ï¼‰ã€‚

---

### 5.2 ç¼“å­˜ä¼˜åŒ–

æ·»åŠ LRUç¼“å­˜ä»¥é¿å…é‡å¤è®¡ç®—ï¼š

```python
from functools import lru_cache
import hashlib

def _make_cache_key(user_input: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return hashlib.md5(user_input.encode()).hexdigest()

# æ·»åŠ ç¼“å­˜è£…é¥°å™¨ï¼ˆä»…ç”¨äºè·¯å¾„Aï¼Œè·¯å¾„Bå› LLMä¸ç¨³å®šæ€§ä¸å»ºè®®ç¼“å­˜ï¼‰
@lru_cache(maxsize=128)
def _cached_path_a(input_hash: str, collection_name: str, top_k: int):
    """ç¼“å­˜è·¯å¾„Açš„ç»“æœï¼ˆå†…éƒ¨å‡½æ•°ï¼‰"""
    # å®é™…è°ƒç”¨é€šè¿‡å¤–éƒ¨å‡½æ•°ä¼ å…¥collection
    pass

# åœ¨path_a_global_embeddingä¸­é›†æˆç¼“å­˜
# ï¼ˆè¯¦ç»†å®ç°ç•¥ï¼Œéœ€è€ƒè™‘collectionå¯¹è±¡æ— æ³•ç›´æ¥ç¼“å­˜çš„é—®é¢˜ï¼‰
```

---

## 6. éƒ¨ç½²ä¸ç›‘æ§

### 6.1 éƒ¨ç½²æ£€æŸ¥æ¸…å•

```bash
# 1. ç¡®è®¤OllamaæœåŠ¡è¿è¡Œ
ollama list | grep swallow
ollama list | grep kun432

# 2. ç¡®è®¤ChromaDBæ•°æ®å®Œæ•´
python -c "
import chromadb
client = chromadb.PersistentClient(path='./chroma_db')
print('gomi:', client.get_collection('gomi').count())
"

# 3. è¿è¡Œå•å…ƒæµ‹è¯•
cd rag && python -m pytest test_hybrid.py -v

# 4. è¿è¡ŒåŸºå‡†æµ‹è¯•
python benchmark_hybrid.py

# 5. ç¯å¢ƒå˜é‡é…ç½®
export ENABLE_HYBRID_GROUNDING=true

# 6. å¯åŠ¨åç«¯æœåŠ¡
cd backend && python -m uvicorn app:app --reload --port 8000

# 7. å¯åŠ¨å‰ç«¯
cd front-streaming && streamlit run app.py
```

### 6.2 æ€§èƒ½ç›‘æ§æŒ‡æ ‡

åœ¨ `backend/app.py` ä¸­æ·»åŠ ç›‘æ§æ—¥å¿—ï¼š

```python
import time

@app.post("/api/bot/respond")
async def rag_respond(req: PromptRequest):
    t_start = time.perf_counter()
    
    rag_prompt, references = rag_retrieve_extended(
        req.prompt,
        gomi_collection,
        knowledge_collection=knowledge_collection,
        area_collection=area_collection,
        known_items=known_items,
        area_meta=area_meta,
        top_k=2,
        use_hybrid=ENABLE_HYBRID_GROUNDING
    )
    
    t_rag_end = time.perf_counter()
    
    reply = ask_ollama(rag_prompt)
    
    t_end = time.perf_counter()
    
    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    metrics = {
        "rag_time_ms": (t_rag_end - t_start) * 1000,
        "llm_time_ms": (t_end - t_rag_end) * 1000,
        "total_time_ms": (t_end - t_start) * 1000,
        "hybrid_enabled": ENABLE_HYBRID_GROUNDING
    }
    
    print(f"â±ï¸ Metrics: {metrics}")
    
    return {
        "reply": reply,
        "references": references,
        "metrics": metrics  # å¯é€‰ï¼šè¿”å›ç»™å‰ç«¯
    }
```

### 6.3 é™çº§ç­–ç•¥é…ç½®

åˆ›å»ºé…ç½®æ–‡ä»¶ `backend/hybrid_config.yaml`ï¼š

```yaml
hybrid_grounding:
  enabled: true
  
  # å¿«é€Ÿè·¯å¾„é˜ˆå€¼
  short_input_threshold: 20
  
  # å¹¶è¡Œæ‰§è¡Œ
  enable_parallel: true
  
  # è¶…æ—¶é…ç½®
  path_b_timeout_seconds: 5
  
  # ç½®ä¿¡åº¦é˜ˆå€¼
  confidence:
    high: 0.45
    low: 0.30
    ambiguity: 0.05
  
  # é™çº§ç­–ç•¥
  degradation:
    # è·¯å¾„Bå¤±è´¥Næ¬¡åè‡ªåŠ¨ç¦ç”¨ï¼ˆé‡å¯æ¢å¤ï¼‰
    max_path_b_failures: 10
    
    # å¹³å‡å»¶è¿Ÿè¶…è¿‡é˜ˆå€¼æ—¶ç¦ç”¨è·¯å¾„B
    max_avg_latency_ms: 600
```

---

## 7. æ•…éšœæ’æŸ¥

### 7.1 å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

| é—®é¢˜ | ç—‡çŠ¶ | æ’æŸ¥æ­¥éª¤ | è§£å†³æ–¹æ¡ˆ |
|-----|------|---------|---------|
| è·¯å¾„Bè¿”å›ç©ºåˆ—è¡¨ | LLMæœªæå–åˆ°å€™é€‰ | 1. æ£€æŸ¥OllamaæœåŠ¡<br>2. æŸ¥çœ‹LLMè¾“å‡ºæ—¥å¿— | 1. è°ƒæ•´LLM prompt<br>2. é™ä½temperature |
| ç½®ä¿¡åº¦æ™®éåä½ | æ‰€æœ‰è¾“å…¥confidence=low | æ£€æŸ¥Embeddingæ¨¡å‹åŠ è½½ | 1. é‡æ–°åŠ è½½æ¨¡å‹<br>2. è°ƒæ•´é˜ˆå€¼ |
| å»¶è¿Ÿè¿‡é«˜ | å“åº”æ—¶é—´>1s | 1. æ£€æŸ¥å¹¶è¡Œæ‰§è¡Œå¼€å…³<br>2. æŸ¥çœ‹GPUå ç”¨ | 1. å¯ç”¨å¹¶è¡Œ<br>2. ä¼˜åŒ–batch size |
| è·¯å¾„Aå’Œè·¯å¾„Bç»“æœå·®å¼‚å¤§ | mergeåç»“æœæ··ä¹± | æ‰“å°ä¸¤ä¸ªè·¯å¾„çš„å€™é€‰ | è°ƒæ•´mergeæƒé‡ç­–ç•¥ |

### 7.2 è°ƒè¯•å·¥å…·

åˆ›å»ºè°ƒè¯•è„šæœ¬ `rag/debug_hybrid.py`ï¼š

```python
#!/usr/bin/env python3
"""
Hybridç³»ç»Ÿè°ƒè¯•å·¥å…·
"""

import sys
from hybrid_grounding import hybrid_grounding, format_grounding_result
from rag_demo3 import load_jsonl, build_chroma

def debug_input(user_input: str):
    """è°ƒè¯•å•ä¸ªè¾“å…¥"""
    print(f"\n{'='*80}")
    print(f"è°ƒè¯•è¾“å…¥: {user_input}")
    print(f"{'='*80}")
    
    # åŠ è½½collection
    gomi_docs, gomi_meta = load_jsonl("rag_docs_merged.jsonl", key="å“å")
    gomi_collection = build_chroma(gomi_docs, gomi_meta, name="gomi")
    
    # æ‰§è¡ŒHybridæŒ‡ç§°ï¼ˆå¼ºåˆ¶å®Œæ•´è·¯å¾„ï¼‰
    result = hybrid_grounding(
        user_input,
        gomi_collection,
        force_full_path=True
    )
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    print(format_grounding_result(result))
    
    # è¿”å›å€™é€‰è¯¦æƒ…
    print("\nè¯¦ç»†å€™é€‰ä¿¡æ¯:")
    for i, c in enumerate(result.candidates, 1):
        print(f"\n  å€™é€‰ {i}:")
        print(f"    å“å: {c.item_name}")
        print(f"    ç›¸ä¼¼åº¦: {c.similarity:.4f}")
        print(f"    æ¥æº: {c.source}")
        print(f"    å‡ºã—æ–¹: {c.metadata.get('å‡ºã—æ–¹', 'N/A')[:50]}...")
        print(f"    å‚™è€ƒ: {c.metadata.get('å‚™è€ƒ', 'N/A')[:50]}...")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python debug_hybrid.py <ç”¨æˆ·è¾“å…¥>")
        print('ç¤ºä¾‹: python debug_hybrid.py "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’æ¨ã¦ãŸã„"')
        sys.exit(1)
    
    user_input = " ".join(sys.argv[1:])
    debug_input(user_input)
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
cd rag
python debug_hybrid.py "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’å‡¦åˆ†ã—ãŸã„"
```

---

## 8. é™„å½•

### 8.1 æ€§èƒ½åŸºå‡†å‚è€ƒ

| åœºæ™¯ | è¾“å…¥ç±»å‹ | é¢„æœŸå»¶è¿Ÿ | é¢„æœŸå‡†ç¡®ç‡ |
|-----|---------|---------|-----------|
| çŸ­æŒ‡ä»¤ | <20å­—ç¬¦ | <150ms | >90% |
| ä¸­ç­‰è¾“å…¥ | 20-50å­—ç¬¦ | <300ms | >85% |
| é•¿æ–‡æœ¬ | >50å­—ç¬¦ | <500ms | >80% |

### 8.2 ç›¸å…³æ–‡æ¡£

- [RAG_IMPROVEMENT_0201.md](RAG_IMPROVEMENT_0201.md) - è®¾è®¡æ–¹æ¡ˆ
- [RAG_SYSTEM_ARCHITECTURE.md](RAG_SYSTEM_ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„
- [BACKEND_ARCHITECTURE.md](../backend/BACKEND_ARCHITECTURE.md) - åç«¯è®¾è®¡

### 8.3 å˜æ›´æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | å˜æ›´å†…å®¹ |
|-----|------|---------|
| 2026-02-01 | v1.0 | åˆå§‹ç‰ˆæœ¬ |

---

**æ–‡æ¡£ç»´æŠ¤**: å¼€å‘å›¢é˜Ÿ  
**æœ€åæ›´æ–°**: 2026-02-01
