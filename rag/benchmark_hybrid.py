#!/usr/bin/env python3
"""
Hybridå“åæŒ‡ç§°ç³»ç»Ÿ - ç«¯åˆ°ç«¯åŸºå‡†æµ‹è¯•
ç‹¬ç«‹è¿è¡Œï¼Œè¯„ä¼°ç³»ç»Ÿæ€§èƒ½å’Œå‡†ç¡®æ€§
"""

import json
import time
from pathlib import Path
from hybrid_grounding import hybrid_grounding, format_grounding_result
from rag_demo3 import load_jsonl, build_chroma
import chromadb


def load_or_create_test_cases():
    """åŠ è½½æˆ–åˆ›å»ºæµ‹è¯•ç”¨ä¾‹"""
    test_file = Path("test_inputs.json")
    
    if not test_file.exists():
        # åˆ›å»ºé»˜è®¤æµ‹è¯•ç”¨ä¾‹
        test_data = {
            "description": "Hybridå“åæŒ‡ç§°ç³»ç»ŸåŸºå‡†æµ‹è¯•æ•°æ®é›†",
            "version": "1.0",
            "test_cases": [
                # çŸ­è¾“å…¥æµ‹è¯•
                {
                    "input": "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’æ¨ã¦ãŸã„",
                    "expected_keywords": ["ãƒ‘ã‚½ã‚³ãƒ³", "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"],
                    "type": "short",
                    "description": "å•ä¸€å“åï¼Œæ˜ç¡®æ„å›¾"
                },
                {
                    "input": "å†·è”µåº«",
                    "expected_keywords": ["å†·è”µåº«"],
                    "type": "short",
                    "description": "å•è¯è¾“å…¥"
                },
                {
                    "input": "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯è£½ã®åç´ç®±",
                    "expected_keywords": ["ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯", "åç´", "ç®±"],
                    "type": "short",
                    "description": "å¸¦ä¿®é¥°çš„å“å"
                },
                # ä¸­ç­‰é•¿åº¦è¾“å…¥
                {
                    "input": "å¤ã„ãƒ†ãƒ¬ãƒ“ã‚’å‡¦åˆ†ã—ãŸã„ã§ã™",
                    "expected_keywords": ["ãƒ†ãƒ¬ãƒ“"],
                    "type": "medium",
                    "description": "ç®€å•å¥å­"
                },
                {
                    "input": "å£Šã‚ŒãŸé›»å­ãƒ¬ãƒ³ã‚¸ãŒã‚ã‚‹ã‚“ã§ã™ãŒ",
                    "expected_keywords": ["é›»å­ãƒ¬ãƒ³ã‚¸", "ãƒ¬ãƒ³ã‚¸"],
                    "type": "medium",
                    "description": "æ—¥å¸¸å£è¯­è¡¨è¾¾"
                },
                # é•¿æ–‡æœ¬è¾“å…¥ï¼ˆå¤šå“åï¼‰
                {
                    "input": "å¼•ã£è¶Šã—ã§ä½¿ã‚ãªããªã£ãŸãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨å¤ã„ãƒ—ãƒªãƒ³ã‚¿ãƒ¼ã€ãã‚Œã‹ã‚‰å£Šã‚ŒãŸé›»å­ãƒ¬ãƒ³ã‚¸ã‚’å‡¦åˆ†ã—ãŸã„ã§ã™",
                    "expected_keywords": ["ãƒ‘ã‚½ã‚³ãƒ³", "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼", "é›»å­ãƒ¬ãƒ³ã‚¸", "ãƒ¬ãƒ³ã‚¸"],
                    "type": "long",
                    "description": "å¤šå“åé•¿æ–‡æœ¬"
                },
                {
                    "input": "å­ä¾›ãŒå¤§ãããªã£ãŸã®ã§ã€ãƒ™ãƒ“ãƒ¼ã‚«ãƒ¼ã‚„ãƒ™ãƒ“ãƒ¼ãƒ™ãƒƒãƒ‰ã€ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ¨ã¦ãŸã„",
                    "expected_keywords": ["ãƒ™ãƒ“ãƒ¼ã‚«ãƒ¼", "ãƒ™ãƒ“ãƒ¼ãƒ™ãƒƒãƒ‰", "ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆ"],
                    "type": "long",
                    "description": "å¤šä¸ªè‚²å„¿ç”¨å“"
                },
                {
                    "input": "å¤§æƒé™¤ã§å‡ºãŸä¸è¦ãªå®¶å…·ã€æœºã¨ã‚¤ã‚¹ã¨ã‚¿ãƒ³ã‚¹ã‚’å‡¦åˆ†ã—ãŸã„ã‚“ã§ã™ãŒã€ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹",
                    "expected_keywords": ["æœº", "ã‚¤ã‚¹", "ã‚¿ãƒ³ã‚¹", "å®¶å…·"],
                    "type": "long",
                    "description": "å®¶å…·ç±»å¤šå“å"
                },
                # å¤åˆåè¯æµ‹è¯•
                {
                    "input": "ãƒãƒ¼ãƒˆPC",
                    "expected_keywords": ["ãƒ‘ã‚½ã‚³ãƒ³", "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"],
                    "type": "compound",
                    "description": "å¤åˆåè¯ç¼©å†™"
                },
                {
                    "input": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³",
                    "expected_keywords": ["æºå¸¯é›»è©±", "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³"],
                    "type": "compound",
                    "description": "å¤–æ¥è¯­å¤åˆè¯"
                },
                # æ¨¡ç³Šè¾“å…¥æµ‹è¯•
                {
                    "input": "å®¶é›»è£½å“",
                    "expected_keywords": ["é›»", "å®¶é›»"],
                    "type": "ambiguous",
                    "description": "æ¨¡ç³Šåˆ†ç±»è¯"
                },
                {
                    "input": "å¤§ããªã‚´ãƒŸ",
                    "expected_keywords": ["å¤§", "ã‚´ãƒŸ"],
                    "type": "ambiguous",
                    "description": "ç¬¼ç»Ÿæè¿°"
                }
            ]
        }
        test_file.write_text(json.dumps(test_data, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"âœ… åˆ›å»ºæµ‹è¯•æ•°æ®é›†: {test_file}")
    
    data = json.loads(test_file.read_text(encoding="utf-8"))
    return data["test_cases"]


def evaluate_result(result, expected_keywords):
    """
    è¯„ä¼°ç»“æœå‡†ç¡®æ€§
    
    Returns:
        (is_correct, match_info, reason)
    """
    if not result.primary_candidate:
        return False, None, "æ— ä¸»å€™é€‰"
    
    item_name = result.primary_candidate.item_name
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€é¢„æœŸå…³é”®è¯
    matches = []
    for keyword in expected_keywords:
        if keyword in item_name:
            matches.append(keyword)
    
    if matches:
        return True, matches, f"åŒ¹é…å…³é”®è¯: {', '.join(matches)}"
    else:
        return False, None, f"æœªåŒ¹é…: {item_name}"


def run_benchmark():
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("=" * 80)
    print("Hybridå“åæŒ‡ç§°ç³»ç»Ÿ - åŸºå‡†æµ‹è¯•")
    print("=" * 80)
    
    # åˆå§‹åŒ–collection
    print("\nğŸ“¦ åˆå§‹åŒ–ChromaDB...")
    gomi_docs, gomi_meta = load_jsonl("rag_docs_merged.jsonl", key="å“å")
    gomi_collection = build_chroma(gomi_docs, gomi_meta, name="gomi")
    print(f"âœ… CollectionåŠ è½½å®Œæˆï¼Œå…±{gomi_collection.count()}æ¡è®°å½•")
    
    # åŠ è½½æµ‹è¯•ç”¨ä¾‹
    test_cases = load_or_create_test_cases()
    
    print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}")
    print("-" * 80)
    
    # æ‰§è¡Œæµ‹è¯•
    results = []
    start_time = time.time()
    
    for i, case in enumerate(test_cases, 1):
        user_input = case["input"]
        expected = case["expected_keywords"]
        case_type = case.get("type", "unknown")
        description = case.get("description", "")
        
        print(f"\n[{i}/{len(test_cases)}] {case_type.upper()} - {description}")
        print(f"è¾“å…¥: {user_input}")
        
        # æ‰§è¡ŒHybridæŒ‡ç§°
        result = hybrid_grounding(user_input, gomi_collection, force_full_path=len(user_input) >= 20)
        
        # è¯„ä¼°ç»“æœ
        is_correct, matches, reason = evaluate_result(result, expected)
        
        # è®°å½•ç»“æœ
        results.append({
            "id": i,
            "input": user_input,
            "type": case_type,
            "description": description,
            "expected": expected,
            "primary_candidate": result.primary_candidate.item_name if result.primary_candidate else None,
            "similarity": result.primary_candidate.similarity if result.primary_candidate else 0,
            "confidence": result.confidence_level,
            "is_ambiguous": result.is_ambiguous,
            "execution_time_ms": result.execution_time_ms,
            "path_used": result.path_used,
            "is_correct": is_correct,
            "matches": matches,
            "reason": reason,
            "all_candidates": [c.item_name for c in result.candidates[:3]]
        })
        
        # æ‰“å°ç»“æœ
        status = "âœ…" if is_correct else "âŒ"
        print(f"{status} ä¸»å€™é€‰: {result.primary_candidate.item_name if result.primary_candidate else 'None'}")
        print(f"   ç›¸ä¼¼åº¦: {result.primary_candidate.similarity:.3f if result.primary_candidate else 0}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence_level} | æ­§ä¹‰: {result.is_ambiguous}")
        print(f"   è·¯å¾„: {result.path_used} | è€—æ—¶: {result.execution_time_ms:.2f}ms")
        print(f"   è¯„ä¼°: {reason}")
    
    total_time = time.time() - start_time
    
    # ========== ç»Ÿè®¡æ€»ç»“ ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»Ÿè®¡æ€»ç»“")
    print("=" * 80)
    
    total = len(results)
    correct = sum(1 for r in results if r["is_correct"])
    accuracy = correct / total * 100 if total > 0 else 0
    
    avg_time = sum(r["execution_time_ms"] for r in results) / total
    
    print(f"\næ€»ä½“å‡†ç¡®ç‡: {accuracy:.1f}% ({correct}/{total})")
    print(f"å¹³å‡è€—æ—¶: {avg_time:.2f}ms")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    print("\næŒ‰ç±»å‹ç»Ÿè®¡:")
    print(f"{'ç±»å‹':<12} | {'å‡†ç¡®ç‡':<12} | {'å¹³å‡è€—æ—¶':<12} | {'æ ·æœ¬æ•°':<8}")
    print("-" * 55)
    
    type_stats = {}
    for r in results:
        t = r["type"]
        if t not in type_stats:
            type_stats[t] = {"total": 0, "correct": 0, "time": []}
        type_stats[t]["total"] += 1
        if r["is_correct"]:
            type_stats[t]["correct"] += 1
        type_stats[t]["time"].append(r["execution_time_ms"])
    
    for t in sorted(type_stats.keys()):
        stats = type_stats[t]
        t_accuracy = stats["correct"] / stats["total"] * 100
        t_avg_time = sum(stats["time"]) / len(stats["time"])
        print(f"{t:<12} | {t_accuracy:5.1f}% ({stats['correct']}/{stats['total']}) | "
              f"{t_avg_time:9.2f}ms | {stats['total']:>2}")
    
    # è·¯å¾„ä½¿ç”¨ç»Ÿè®¡
    print("\nè·¯å¾„ä½¿ç”¨ç»Ÿè®¡:")
    path_counts = {}
    for r in results:
        path = r["path_used"]
        path_counts[path] = path_counts.get(path, 0) + 1
    
    for path in sorted(path_counts.keys()):
        count = path_counts[path]
        print(f"  {path:<15}: {count:2d} ({count/total*100:.1f}%)")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    print("\nç½®ä¿¡åº¦åˆ†å¸ƒ:")
    confidence_counts = {}
    for r in results:
        conf = r["confidence"]
        confidence_counts[conf] = confidence_counts.get(conf, 0) + 1
    
    for conf in ["high", "medium", "low"]:
        count = confidence_counts.get(conf, 0)
        print(f"  {conf:<8}: {count:2d} ({count/total*100:.1f}%)")
    
    # å¤±è´¥æ¡ˆä¾‹åˆ†æ
    failures = [r for r in results if not r["is_correct"]]
    if failures:
        print(f"\nâŒ å¤±è´¥æ¡ˆä¾‹ ({len(failures)}ä¸ª):")
        for f in failures:
            print(f"\n  [{f['id']}] {f['type']} - {f['description']}")
            print(f"  è¾“å…¥: {f['input']}")
            print(f"  é¢„æœŸ: {f['expected']}")
            print(f"  å®é™…: {f['primary_candidate']}")
            print(f"  åŸå› : {f['reason']}")
    
    # æ€§èƒ½åˆ†æ
    print("\nâ±ï¸ æ€§èƒ½åˆ†æ:")
    fast_queries = sum(1 for r in results if r["execution_time_ms"] < 200)
    slow_queries = sum(1 for r in results if r["execution_time_ms"] > 500)
    print(f"  <200ms: {fast_queries} ({fast_queries/total*100:.1f}%)")
    print(f"  200-500ms: {total - fast_queries - slow_queries} ({(total-fast_queries-slow_queries)/total*100:.1f}%)")
    print(f"  >500ms: {slow_queries} ({slow_queries/total*100:.1f}%)")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = Path("benchmark_results.json")
    output_file.write_text(
        json.dumps({
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {
                "total": total,
                "correct": correct,
                "accuracy": accuracy,
                "avg_time_ms": avg_time,
                "total_time_s": total_time,
                "type_stats": {
                    t: {
                        "accuracy": stats["correct"] / stats["total"] * 100,
                        "avg_time_ms": sum(stats["time"]) / len(stats["time"]),
                        "samples": stats["total"]
                    }
                    for t, stats in type_stats.items()
                }
            },
            "results": results
        }, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # è¯„ä¼°æ˜¯å¦è¾¾æ ‡
    print("\n" + "=" * 80)
    target_accuracy = 85
    if accuracy >= target_accuracy:
        print(f"âœ… æµ‹è¯•é€šè¿‡ï¼å‡†ç¡®ç‡ {accuracy:.1f}% è¾¾åˆ°ç›®æ ‡ {target_accuracy}%")
        print("=" * 80)
        return True
    else:
        print(f"âŒ æµ‹è¯•æœªè¾¾æ ‡ã€‚å‡†ç¡®ç‡ {accuracy:.1f}% ä½äºç›®æ ‡ {target_accuracy}%")
        print(f"   å·®è·: {target_accuracy - accuracy:.1f}%")
        print("=" * 80)
        return False


def run_single_test(user_input: str):
    """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    print("=" * 80)
    print("å•æµ‹è¯•æ¨¡å¼")
    print("=" * 80)
    
    print("\nåˆå§‹åŒ–ChromaDB...")
    gomi_docs, gomi_meta = load_jsonl("rag_docs_merged.jsonl", key="å“å")
    gomi_collection = build_chroma(gomi_docs, gomi_meta, name="gomi")
    
    print(f"\nè¾“å…¥: {user_input}\n")
    
    result = hybrid_grounding(user_input, gomi_collection, force_full_path=True)
    
    print(format_grounding_result(result))
    
    if result.primary_candidate:
        print("\nè¯¦ç»†ä¿¡æ¯:")
        print(f"å‡ºã—æ–¹: {result.primary_candidate.metadata.get('å‡ºã—æ–¹', 'N/A')}")
        print(f"å‚™è€ƒ: {result.primary_candidate.metadata.get('å‚™è€ƒ', 'N/A')}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # å•æµ‹è¯•æ¨¡å¼
        user_input = " ".join(sys.argv[1:])
        run_single_test(user_input)
    else:
        # å®Œæ•´åŸºå‡†æµ‹è¯•
        success = run_benchmark()
        sys.exit(0 if success else 1)
